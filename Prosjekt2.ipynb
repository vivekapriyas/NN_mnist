{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <center>\n",
    "        TMA4320 Prosjekt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formålet med prosjektet er å gi en introduksjon til maskinlæring, nærmere bestemt dyplæring og dype nevrale nettverk, ved egen implementering av algoritmene. \n",
    "Ideen er å trene dataprogrammet til å gjenkjenne bildeelementer i to ulike testproblemer. I det første testproblemet er problemstillingen forenklet til gjenkjenning av fargede datapunkt, mens i det andre testproblemet skal programmet kunne skille mellom to ulike håndskrevne sifre. \n",
    "Denne rapporten skal først presentere den grunneleggende algoritmen som benyttes i treningsfasen og hovedsaklig er lik for begge problemstillingene, før hver problemstilling blir framstilt i detalj.\n",
    "Valg av startparametre skal begrunnes og parametrene som ble funnet i treningsfasen skal presenteres. Deretter skal modellen med disse fikserte parametrene kjøres med nye data og resultatene bli lagt fram og diskutert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager w_k og b_k\n",
    "\n",
    "def W(d=2, K=3):\n",
    "    w_k=np.random.randn(K,d,d)\n",
    "    b_k=np.random.randn(K,d)\n",
    "    return w_k,  b_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.23840584  1.9993293   1.9993293 ]\n",
      " [ 0.03597242  1.9993293   1.9993293 ]]\n",
      "Y_1:  [[1.99505475 0.96402758 2.99999977]\n",
      " [1.96402758 1.96402758 3.9993293 ]]\n",
      "Y_2:  [[2.99495622 1.96325312 3.99999955]\n",
      " [2.96402564 2.96401233 4.9993293 ]]\n",
      "Z: [0.99905084 0.99734133 0.99995457]\n",
      "Prod:  [6.95898186 5.92726546 9.99932885]\n",
      "Prod_to_re_use:  [9.48260712e-04 2.65160573e-03 4.54262826e-05]\n",
      "[-9.49161620e-04  9.97341326e-01 -4.54283464e-05]\n",
      "J_diff_my:  0.0026436538598699254\n",
      "0.0026436538598699254\n",
      "J_diff_my:  [0.00518923 0.00783582]\n",
      "P_K= [[-9.00052673e-07  2.64455598e-03 -2.06364090e-09]\n",
      " [-9.00052673e-07  2.64455598e-03 -2.06364090e-09]]\n",
      "P_k_liste:  [array([[-9.09115273e-07,  2.83586627e-03, -2.06364276e-09],\n",
      "       [-9.81602990e-07,  3.21022271e-03, -2.06641093e-09]]), array([[-9.00233535e-07,  2.64873122e-03, -2.06364183e-09],\n",
      "       [-9.00237026e-07,  2.64881187e-03, -2.06364183e-09]]), array([[-9.00052673e-07,  2.64455598e-03, -2.06364090e-09],\n",
      "       [-9.00052673e-07,  2.64455598e-03, -2.06364090e-09]])]\n",
      "[[1. 2.]\n",
      " [0. 1.]]\n",
      "[[1. 0. 2.]\n",
      " [1. 1. 3.]]\n",
      "W_jY_j:  [[3. 2. 8.]\n",
      " [1. 1. 3.]]\n",
      "b_j_mat:  [[0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "[[1. 1.]\n",
      " [1. 2.]]\n",
      "[[1.99505475 0.96402758 2.99999977]\n",
      " [1.96402758 1.96402758 3.9993293 ]]\n",
      "W_jY_j:  [[ 3.95908233  2.92805516  6.99932907]\n",
      " [ 5.92310991  4.89208274 10.99865837]]\n",
      "b_j_mat:  [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "J_diff_W_matrix:  [array([[-8.88173937e-09,  1.87126164e-04],\n",
      "       [-6.36080230e-08,  1.87077133e-04]]), array([[3.94694896e-06, 8.04154980e-06],\n",
      "       [7.77425248e-08, 1.58393324e-07]])]\n",
      "J_diff_b_vec:  [array([0.00027806, 0.00027801]), array([5.00537469e-05, 7.26115617e-06])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([[-8.88173937e-09,  1.87126164e-04],\n",
       "         [-6.36080230e-08,  1.87077133e-04]]),\n",
       "  array([[3.94694896e-06, 8.04154980e-06],\n",
       "         [7.77425248e-08, 1.58393324e-07]])],\n",
       " [array([0.00027806, 0.00027801]), array([5.00537469e-05, 7.26115617e-06])],\n",
       " array([0.00518923, 0.00783582]),\n",
       " 0.0026436538598699254)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 1\n",
    "#Definerer konstant for antall lag:\n",
    "K = 2\n",
    "\n",
    "#Finner Y_k+1\n",
    "#Trenger først sigma, aktiveringsfunksjonen\n",
    "def sigma(x):\n",
    "    return(np.tanh(x))\n",
    "#     Dersom vi heller vil bruke max(), nå må x kun være vektor, denne må utvides:\n",
    "#     Denne er brukt til å teste funksjonene\n",
    "#     if isinstance(x, (np.ndarray, list)):\n",
    "#         returliste = []\n",
    "#         for element in x:\n",
    "#             returliste.append(max(element, 0))\n",
    "#         return(np.array(returliste))\n",
    "#     else:\n",
    "#         return(max(0, x))\n",
    "\n",
    "#Sigma derivert analytisk\n",
    "def sigma_diff(x):\n",
    "    return(1-np.tanh(x)**2)\n",
    "\n",
    "def eta(x):\n",
    "    return(np.exp(x)/(np.exp(x)+1))\n",
    "\n",
    "#Analytisk løsning av derivasjon av eta\n",
    "def eta_diff(x):\n",
    "    return(np.exp(x)/(np.exp(x) + 1)**2)\n",
    "    \n",
    "def checkArray(array, string):\n",
    "    if isinstance(array, list):\n",
    "        return(np.array(array))\n",
    "    elif not isinstance(array, np.ndarray):\n",
    "        raise ValueError(string, \"was not an np.ndarray.\")\n",
    "        \n",
    "#Hjelpefunskjon for å regne ut vektorproduktet V_1@V_2^T\n",
    "#Denne vil altså returnere en matrise, ikke en skalar størrelse\n",
    "def makeMatrixFromVec(a, b):\n",
    "    return_matrix = np.zeros((len(a), len(b)))\n",
    "    for i in range(len(b)):\n",
    "        return_matrix[:, i] = b[i]*a\n",
    "    return(return_matrix)\n",
    "    \n",
    "def findNextYVec(Y_k, W_k, b_k):\n",
    "    #Denne funksjonen skal finne Y_k+1 = Y_k + h sigma(W_k * Y_k + b_k)\n",
    "    #Y er en matrise (dxI), W er en matrise (dxd) og b er en vektor\n",
    "    #Her er sigma en skalar funksjon som anvendes komponentvis på vektoren.\n",
    "    #All input skal være np.ndarrays, men b_k vil være den eneste som lager krøll\n",
    "    checkArray(b_k, 'b_k')\n",
    "    # Finner produktet W_k * Y_k og legger til b_k\n",
    "    vec_for_sigma = np.dot(W_k, Y_k) + b_k\n",
    "    #Anvender sigma elementvis\n",
    "    sigma_vec = sigma(vec_for_sigma)\n",
    "    #Avkommenter for å sjekke at sigma gjør som den skal\n",
    "    #print(vec_for_sigma)\n",
    "    #print(sigma_vec)\n",
    "    return(Y_k+h*sigma_vec)\n",
    "\n",
    "def findNextYMat(Y_k_mat, W_k, b_k):\n",
    "    #Shape[1] finner antall kolonner\n",
    "    #Shape[0] finner antall rader, dvs. samme som len()\n",
    "    numberOfColumns = Y_k_mat.shape[1]\n",
    "    nextYMat = np.array([np.array([0.0 for i in range(numberOfColumns)]) for e in range(Y_k_mat.shape[0])])\n",
    "    for column in range(numberOfColumns):\n",
    "        Y_k = Y_k_mat[:, column]\n",
    "        nextYMat[:, column] = findNextYVec(Y_k, W_k, b_k)\n",
    "    return(np.array(nextYMat))\n",
    "\n",
    "#Legger ved matrisene jeg har brukt for å sjekke at alt fungerer som det skal\n",
    "A = np.array([[1, 2], [2, 1]])\n",
    "Y_k_mat = np.array([np.array([-2, 1, 1]), np.array([1, 1, 1])])\n",
    "print(findNextYMat(Y_k_mat, A, np.array([1, 1])))\n",
    "#Her er altså b_k = [1, 1]\n",
    "\n",
    "#Hjelpefunksjon som vi strengt tatt definerer på nytt senere, men det er denne jeg har brukt i testene\n",
    "def findZvalue(Y_k_mat, w_vec, my):\n",
    "    #w og my er konstante mellom alle K-lag, men endres for for iterasjon\n",
    "    #Skal regne ut eta(Y_k^T * w + my * [1 for i in range(len(w))]\n",
    "    vec_for_eta = np.dot(w_vec, Y_k_mat) + my #np.array([my for i in range(Y_k_mat.shape[1])])\n",
    "    #Kan også regne ut:\n",
    "    #Y_T = np.transpose(Y_k_mat)\n",
    "    #vec_for_eta = np.dot(Y_T, w) + np.array([w for i in range(len(w))])\n",
    "    #print(vec_for_eta)\n",
    "    return(eta(vec_for_eta))\n",
    "\n",
    "def findGradJ(Z_vec, W_K, Y_K, Y_end, w_vec, c_vec, my, b_K):\n",
    "    #Til kodeoptimalisering - et produkt går igjen: eta_diff(Y_K^T * w_vec + my*Vec1)\n",
    "    print(\"Prod: \", np.dot(w_vec, Y_end)+my)\n",
    "    prod_to_re_use = eta_diff(np.dot(w_vec, Y_end)+my) #np.array([my for i in range(len(Z_vec))]))\n",
    "    print(\"Prod_to_re_use: \", prod_to_re_use)\n",
    "    print(Z_vec - c_vec)\n",
    "    print(\"J_diff_my: \", np.dot(prod_to_re_use, Z_vec-c_vec))\n",
    "    #Dette kommer egentlig til slutt, men starter der:\n",
    "    #Z befinner seg inni U\n",
    "    J_diff_my = 0\n",
    "    for i in range(len(Z_vec)):\n",
    "        J_diff_my += (Z_vec[i]-c_vec[i])*eta_diff(np.dot(w_vec, Y_end[:, i])+my)\n",
    "    print(J_diff_my)\n",
    "    #J_diff_my sjekket for hånd!\n",
    "    #dJ/dw  = Y_K * [(Z-c)had*eta_diff(Y_K^T*w + my*1Vec]\n",
    "    #had* er hadamard-produktet, som bare er å gange sammen alle elementene for seg, 1Vec er en vektor fylt med enere\n",
    "    diff_my_vec_for_product = np.multiply(Z_vec - c_vec, eta_diff(np.dot(w_vec, Y_end)+my))\n",
    "    J_diff_w = np.dot(Y_end, diff_my_vec_for_product)\n",
    "    print(\"J_diff_my: \", J_diff_w)\n",
    "    #Definerer P_K = dJ/dY_K\n",
    "    #P_K er altså en matrise\n",
    "    #dJ/dY_K = w_vec * [(Z_vec - c_vec)had*eta_diff(Y_K^T * w_vec + my*Vec1)]^T      NB: Husk transponering\n",
    "    #Rekursivt:\n",
    "    #P_k-1: P_k + h*W_k-1^T*[sigma_diff(W_k-1*Y_k-1 + b_k-1)had*P_k)\n",
    "    P_K = makeMatrixFromVec(w_vec, np.multiply(Z_vec - c_vec, prod_to_re_use))\n",
    "    #Ønsker nå å samle opp for alle de deriverte k < K:\n",
    "    P_k_liste = [P_K]\n",
    "    print(\"P_K=\",P_K)\n",
    "    #Ønsker å lage b_k som en matrise, b_k har samme dimensjon som en kolonne av WdotY, men den må være like lang\n",
    "    for i in range(K-1, -1, -1):\n",
    "        WdotY = np.dot(W_K[i], Y_K[i])\n",
    "        b_i_mat = np.array([np.array([b_K[j][i] for e in range(WdotY.shape[1])]) for j in range(WdotY.shape[0])])\n",
    "        matrix_for_sigma_diff =  WdotY + b_i_mat #Transponer denne!\n",
    "        matrix_for_product = np.multiply(sigma_diff(matrix_for_sigma_diff), P_k_liste[0])\n",
    "        P_i = P_k_liste[0] + h * np.dot(np.transpose(W_K[i]), matrix_for_product)\n",
    "        P_k_liste.insert(0, P_i)\n",
    "    print(\"P_k_liste: \", P_k_liste)\n",
    "    #Har nå funnet alle P_k, og kan begynne å regne ut de deriverte.\n",
    "    J_diff_W_matrix = []\n",
    "    #dJ/dW_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*Y_k^T\n",
    "    J_diff_b_vec = []\n",
    "    #dJ/db_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*\n",
    "    for j in range(K):\n",
    "        print(W_K[j])\n",
    "        print(Y_K[j])\n",
    "        W_jY_j = np.dot(W_K[j], Y_K[j])\n",
    "        print(\"W_jY_j: \", W_jY_j)\n",
    "        b_j_mat = np.array([np.array([b_K[c][j] for e in range(W_jY_j.shape[1])]) for c in range(W_jY_j.shape[0])])\n",
    "        print(\"b_j_mat: \", b_j_mat)\n",
    "        one_vector = np.array([1.0 for e in range(W_jY_j.shape[1])])\n",
    "        J_diff_W_matrix.append(h*np.dot(P_k_liste[j+1]*sigma_diff(W_jY_j + b_j_mat), np.transpose(Y_K[j])))\n",
    "        J_diff_b_vec.append(h*np.dot(P_k_liste[j+1]*eta_diff(W_jY_j + b_j_mat), one_vector))\n",
    "    print(\"J_diff_W_matrix: \", J_diff_W_matrix)\n",
    "    print(\"J_diff_b_vec: \", J_diff_b_vec)\n",
    "    return(J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my)\n",
    "\n",
    "#Notat: Nå har jeg lagt inn gradientfunksjonen, og den kjører i pycharm, men ikke alle returverdier er sjekket for hånd\n",
    "#Her er testene heg har brukt\n",
    "Y_0 = np.array([np.array([1.0,0.0,2.0]), np.array([1, 1, 3])])\n",
    "W_2 = [np.array([np.array([1.0, 2.0]), np.array([0.0, 1.0])]), np.array([np.array([1.0, 1.0]),np.array([1.0, 2.0])])]\n",
    "b_2 = [np.array([0.0, 1.0]), np.array([1.0, 1.0])]\n",
    "w = np.array([1.0, 1.0])\n",
    "my = 1\n",
    "c_vec = np.array([1, 0, 1])\n",
    "\n",
    "#Har regnet at Y_1 stemmer for hånd\n",
    "Y_1 = findNextYMat(Y_0, W_2[0], b_2[0])\n",
    "Y_2 = findNextYMat(Y_1, W_2[1], b_2[1])\n",
    "print(\"Y_1: \", Y_1)\n",
    "print(\"Y_2: \", Y_2)\n",
    "\n",
    "Y_K2 = np.array([Y_0, Y_1])\n",
    "Y_end = Y_2\n",
    "\n",
    "Z_vec = findZvalue(Y_end, w, my)\n",
    "print(\"Z:\",Z_vec)\n",
    "findGradJ(Z_vec, W_2, Y_K2, Y_end, w, c_vec, my, b_2)\n",
    "\n",
    "#Det må veriseres at J_diff_b_k og J_diff_W gjør som de skal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager Z\n",
    "def n(x):\n",
    "    return (np.exp(x))/(np.exp(x)+1)\n",
    "\n",
    "def Z(Y_k, w, u, n):\n",
    "    vec=Y_k.transpose()@w + u*np.ones(((Y_k.transpose()@w).size), dtype=int)\n",
    "    return n(vec)\n",
    "\n",
    "print(Z(Y_k,w,u,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lager J\n",
    "\n",
    "def J(Z,c):\n",
    "    return 0.5*np.linalg.norm(Z-c)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lager neste U, dvs. parametrene\n",
    "\n",
    "def U_jPLussEn(Uj,tau,gradJ):\n",
    "    Uj = Uj - tau*gradJ\n",
    "    return Uj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam descent\n",
    "#litt usikker på hvordan disse ser ut i praksis da/hvorfor det fungerer\n",
    "#Har endret den slik at den tar inn alle parameterene hver for seg i stedet for matrisen U. Det må nok være en for-løkke\n",
    "#tror fortsatt ikke den fungerer\n",
    "\n",
    "def adam(m,v,j,gradJ, W_k, b_k, w, u):\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    alfa = 0.01\n",
    "    epsilon = 1E-8\n",
    "    \n",
    "    for i in range j: \n",
    "        g = gradJ\n",
    "\n",
    "        m = m + (1-beta1)*g\n",
    "        v = v + (1-beta2)*(g*g)\n",
    "\n",
    "        mj = m/(1-beta1**j)\n",
    "        vj = v/(1-beta2**j)\n",
    "\n",
    "        W_kj = W_k - alfa*(mj/(np.sqrt(vj)+epsilon))\n",
    "        b_kj = b_k -alfa*(mj/(np.sqrt(vj)+epsilon))\n",
    "        wj = w - alfa*(mj/(np.sqrt(vj)+epsilon))\n",
    "        uj = u - alfa*(mj/(np.sqrt(vj)+epsilon))\n",
    "\n",
    "    return W_kj, b_kj, wj, uj, m,v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inkluderte funksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_spiral_2d(n_samples=200):\n",
    "    '''Create \"observations\" for training.\n",
    "    \n",
    "    Creates n_samples dots on two intertwined spirals.\n",
    "    The dots are classified based on which spiral they belong to and\n",
    "    then fuzzed by perturbing the coordinates and permuting the ordering.'''\n",
    "    m1 = math.ceil(n_samples / 2)\n",
    "    m2 = n_samples - m1\n",
    "    \n",
    "    n_turns = 1.0\n",
    "    \n",
    "    phi1 = np.pi\n",
    "    d1 = make_spiral(m1, phi1, n_turns)\n",
    "\n",
    "    \n",
    "    phi2 = (phi1 + np.pi) % (2.0 * np.pi)\n",
    "    d2 = make_spiral(m2, phi2, n_turns)\n",
    "    \n",
    "    features = np.hstack((d1, d2))\n",
    "    labels = np.ones((n_samples,1), dtype='bool_')\n",
    "    labels[m1:] = False\n",
    "    \n",
    "    features = features + .05 * np.random.randn(*features.shape)\n",
    "    \n",
    "    indexes = np.random.permutation(n_samples)\n",
    "    features = features[:, indexes]\n",
    "    labels = labels[indexes]\n",
    "\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def make_spiral(m, phi, n_turns):\n",
    "    '''Makes points on a spiral\n",
    "    \n",
    "    This is a utility function for get_data_spiral_2d'''\n",
    "    r = np.linspace(0.1, 1.0, m)\n",
    "    a = np.linspace(0.1, 2.0 * np.pi * n_turns, m)\n",
    "    xs = r * np.cos(a + phi)\n",
    "    ys = r * np.sin(a + phi)\n",
    "    return np.stack([xs, ys])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
