{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <center>\n",
    "        TMA4320 Prosjekt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Innholdsfortegnelse\n",
    "\n",
    "## 1. Introduksjon\n",
    "## 2. Generell algoritme\n",
    "## 3. Første testproblem: Punkter i planet\n",
    "## 4. Andre testproblem: MNIST - siffergjenkjenning\n",
    "## 5. Avslutning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduksjon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formålet med prosjektet er å gi en introduksjon til maskinlæring, nærmere bestemt dyplæring og dype nevrale nettverk, ved egen implementering av algoritmene. \n",
    "Ideen er å trene dataprogrammet til å gjenkjenne bildeelementer i to ulike testproblemer. I det første testproblemet er problemstillingen forenklet til gjenkjenning av fargede datapunkt, mens i det andre testproblemet skal programmet kunne skille mellom to ulike håndskrevne sifre. \n",
    "Denne rapporten skal først presentere den grunneleggende algoritmen som benyttes i treningsfasen og hovedsaklig er lik for begge problemstillingene, før hver problemstilling blir framstilt i detalj.\n",
    "Valg av startparametre skal begrunnes og parametrene som ble funnet i treningsfasen skal presenteres. Deretter skal modellen med disse fikserte parametrene kjøres med nye data og resultatene bli lagt fram og diskutert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generell algoritme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmen for det nevrale nettverket er delt inn i ulike funksjoner for å forenkle kodestrukturen. Først blir det laget fire tilfeldige parametere; $K$ vektere $W_{k}$, $K$ bias $b_{k}$, en vektor $\\omega$ og en skalar $\\mu$. $K$ er totalt antall lag i transformasjonen. Videre blir et bilde $Y_k$ transformert til det neste laget $k+1$ ved hjelp av en vekter, en bias og funksjonen $\\sigma (x)$. Når de  $I$ bildene har blitt transformert gjennom alle lagene blir hver av de projisert ned på en skalar $Z$ ved hjelp av $\\omega$, $\\mu$ og funksjonen $\\eta (x)$. Verdiene for hvert av de $I$ bildene i $Z$ blir sammenliknet med fasitverdiene i $c$, og denne differansen representeres i $J$. For å minimere $J$ blir de fire gradientene til $J$ med hensyn på de ulike parameterne funnet. Deretter blir vekter, bias $\\omega$ og $\\mu$ optimert ved hjelp av enten \"plain vanilla gradient descent\" eller Adam-metoden. Parameterne blir også lagret i en tekstfil for hver transformasjon gjennom de $K$ lagene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import random \n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importerte filer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import load_mnist\n",
    "from loader import get_dataset\n",
    "from spirals import get_data_spiral_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ha en egen boks for parameterne? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treningen av algoritmen, både for punkter i planet og siffergjenkjenning, foregår i funksjonen $trening$. Den er laget slik at det er valgfritt hvilken optimeringsmetode av parameterne man vil bruke. Adam-metoden bruker en tilfeldig trukket bunke med bilder fra de importerte bildefilene som den legger til i matrisen $Y_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trening(images, labels, AdamOrPlain = 'plain', n=1000, h = 0.05, K = 20):\n",
    "    d = 2\n",
    "    W_k, b_k, omega, my = getRandomParam(d, K)\n",
    "    W_k = np.dot(W_k, 1/(d**2))\n",
    "    omega = np.dot(omega, 1/(d**2))\n",
    "\n",
    "    if AdamOrPlain == 'adam':\n",
    "        mW, mb, mOmega, mMy = getStartMandV(W_k,b_k,omega,my)\n",
    "        vW, vb, vOmega, vMy = getStartMandV(W_k, b_k, omega, my)\n",
    "\n",
    "    elif AdamOrPlain == 'plain':\n",
    "        tau = 0.1\n",
    "    else:\n",
    "        print(\"Må være enten adam eller plain\")\n",
    "\n",
    "    J_list = []\n",
    "\n",
    "    for i in range(n):\n",
    "        Y_k = [images]\n",
    "        for i in range(W_k.shape[0]):\n",
    "            Y_next = findNextYMat(Y_k[-1], W_k[i], b_k[i], h)\n",
    "            Y_k.append(Y_next)\n",
    "\n",
    "        z = findZvalue(Y_k[-1], omega, my)\n",
    "        dJdW, dJdb, dJdOmega, dJdMy = findGradJ(z, W_k, Y_k[:-1], Y_k[-1], omega, labels, my, b_k, h, K)\n",
    "\n",
    "        if AdamOrPlain == 'adam':\n",
    "            mW, vW, JW = adam2(mW, vW, dJdW, i + 1)\n",
    "            mb, vb, Jb = adam2(mb, vb, dJdb, i + 1)\n",
    "            mOmega, vOmega, JOmega = adam2(mOmega, vOmega, dJdOmega, i + 1)\n",
    "            mMy, vMy, JMy = adam2(mMy, vMy, dJdMy, i + 1)\n",
    "\n",
    "            W_k -= JW\n",
    "            b_k -= Jb\n",
    "            omega -= JOmega\n",
    "            my -= JMy\n",
    "\n",
    "        elif AdamOrPlain == 'plain':\n",
    "            W_k, b_k, omega, my = newU(W_k, b_k, omega, my, tau, dJdW, dJdb, dJdOmega, dJdMy)\n",
    "\n",
    "        J_list.append(J(z, labels))\n",
    "\n",
    "    return W_k, b_k, omega, my, z, J_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = read_spiral_from_file()\n",
    "W_learned1, b_learned1, omega_learned1, my_learned1, z1, J_list1 = trening(images, labels, h = 0.1, n = 2000, AdamOrPlain = 'adam')\n",
    "success1 = success(z1,labels*1)\n",
    "\n",
    "plotJ(J_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_k1 = forward_function(images, W_learned1, b_learned1, h)\n",
    "#plot_progression(np.array(Y_k1), labels*1)\n",
    "#plot_separation(findZvalue, Y_k1[-1], omega_learned1, my_learned1, labels*1, 2000)\n",
    "plot_model(forward_function, Y_k1[0], W_learned1, b_learned1, 0.1, labels*1, 100)\n",
    "print(success1)\n",
    "#writeParams(W_learned1, b_learned1, omega_learned1, my_learned1, filename = 'spiral_adam_2000_it_0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#den gamle koden\n",
    "def trening1(n=1000, tau=0.01, h = 0.1):\n",
    "    features, labels = read_spiral_from_file()\n",
    "    W_k, b_k, omega, my = getRandomParam(2, K)\n",
    "\n",
    "    c_vec = labels * 1\n",
    "    Y_k = [features]\n",
    "\n",
    "    # m = makeMandV(K, d)\n",
    "    # v = makeMandV(K, d)\n",
    "\n",
    "    mW = np.zeros_like(W_k)\n",
    "    mb = np.zeros_like(b_k)\n",
    "    mOmega = np.zeros_like(omega)\n",
    "    mMy = np.zeros_like(my)\n",
    "\n",
    "    vW = np.zeros_like(W_k)\n",
    "    vb = np.zeros_like(b_k)\n",
    "    vOmega = np.zeros_like(omega)\n",
    "    vMy = np.zeros_like(my)\n",
    "    J_list = []\n",
    "\n",
    "    for i in range(n):\n",
    "        Y_k = [features]\n",
    "        for i in range(W_k.shape[0]):\n",
    "            Y_next = findNextYMat(Y_k[-1], W_k[i], b_k[i], h)\n",
    "            Y_k.append(Y_next)\n",
    "\n",
    "        z_vec = findZvalue(Y_k[-1], omega, my)\n",
    "\n",
    "        # Nå inneholder Y_k ALLE k, dvs at Y_end er med i Y_k, og må derfor skilles ut før Y_k settes inn i\n",
    "        # Gradientfunksjonen\n",
    "\n",
    "        J_diff_W, J_diff_b, J_diff_omega, J_diff_my = findGradJ(z_vec, W_k, Y_k[:-1], Y_k[-1], omega, c_vec, my, b_k, h, K)\n",
    "        # W_k, b_k, omega, my = U_jPlussEn(W_k,b_k,omega,my,tau,J_diff_W,J_diff_b,J_diff_omega,J_diff_my)\n",
    "        \n",
    "        mW, vW, JW = adam2(mW, vW, J_diff_W, i + 1)\n",
    "        mb, vb, Jb = adam2(mb, vb, J_diff_b, i + 1)\n",
    "        mOmega, vOmega, JOmega = adam2(mOmega, vOmega, J_diff_omega, i + 1)\n",
    "        mMy, vMy, JMy = adam2(mMy, vMy, J_diff_my, i + 1)\n",
    "\n",
    "        W_k -= JW\n",
    "        b_k -= Jb\n",
    "        omega -= JOmega\n",
    "        my -= JMy\n",
    "        J_list.append(J(findZvalue(Y_k[-1], omega, my), c_vec))\n",
    "\n",
    "    return (W_k, b_k, omega, my, features, labels, J_list)\n",
    "\n",
    "\n",
    "\n",
    "def MNIST(n, tau = 0.01, h = 0.05, K = 10):\n",
    "    start = timeit.default_timer()\n",
    "    W_k, b_k, omega, my = getRandomParam(28 * 28, 10)\n",
    "    # Vi får svært store verdier, så normerer alle startmatrisene litt\n",
    "    W_k = np.dot(W_k, 1 / (28 ** 2))\n",
    "    omega = np.dot(omega, 1 / (28 ** 2))\n",
    "\n",
    "    mW = np.zeros_like(W_k)\n",
    "    mb = np.zeros_like(b_k)\n",
    "    mOmega = np.zeros_like(omega)\n",
    "    mMy = np.zeros_like(my)\n",
    "\n",
    "    vW = np.zeros_like(W_k)\n",
    "    vb = np.zeros_like(b_k)\n",
    "    vOmega = np.zeros_like(omega)\n",
    "    vMy = np.zeros_like(my)\n",
    "    J_list = []\n",
    "    for i in range(n):\n",
    "        chunk_start = random.randint(0, images.shape[1] - 500)\n",
    "        Y_k = [images[:, chunk_start:chunk_start + 500]]\n",
    "        for i in range(W_k.shape[0]):\n",
    "            Y_next = findNextYMat(Y_k[-1], W_k[i], b_k[i])\n",
    "            Y_k.append(Y_next)\n",
    "        print(\"Ferdig med matrisene\")\n",
    "        z_vec = findZvalue(Y_k[-1], omega, my)\n",
    "        J_diff_W, J_diff_b, J_diff_omega, J_diff_my = findGradJ(z_vec, W_k, Y_k[:-1], Y_k[-1], omega,\n",
    "                                                                C_vec[chunk_start:chunk_start + 500], my, b_k, h, K)\n",
    "        # W_k, b_k, omega, my = U_jPlussEn(W_k,b_k,omega,my,tau,J_diff_W,J_diff_b,J_diff_omega,J_diff_my)\n",
    "\n",
    "        mW, vW, JW = adam2(mW, vW, J_diff_W, i + 1)\n",
    "        mb, vb, Jb = adam2(mb, vb, J_diff_b, i + 1)\n",
    "        mOmega, vOmega, JOmega = adam2(mOmega, vOmega, J_diff_omega, i + 1)\n",
    "        mMy, vMy, JMy = adam2(mMy, vMy, J_diff_my, i + 1)\n",
    "\n",
    "        W_k -= JW\n",
    "        b_k -= Jb\n",
    "        omega -= JOmega\n",
    "        my -= JMy\n",
    "        J_list.append(J(findZvalue(Y_k[-1], omega, my), C_vec[chunk_start:chunk_start + 500]))\n",
    "    print(timeit.default_timer() - start)\n",
    "    return (W_k, b_k, omega, my, J_list)\n",
    "\n",
    "\n",
    "W_k_mnist, b_k_mnist, omega_mnist, my_mnist, J_list_mnist = MNIST(10)\n",
    "Y_k_mnist = [images]\n",
    "J_list_layer = [J(findZvalue(Y_k_mnist[-1], omega_mnist, my_mnist), C_vec)]\n",
    "for i in range(W_k_mnist.shape[0]):\n",
    "    Y_next = findNextYMat(Y_k_mnist[-1], W_k_mnist[i], b_k_mnist[i])\n",
    "    Y_k_mnist.append(Y_next)\n",
    "    J_list_layer.append(J(findZvalue(Y_k_mnist[-1], omega_mnist, my_mnist), C_vec))\n",
    "Y_k_mnist = np.array(Y_k_mnist)\n",
    "# print(J_list_layer)\n",
    "print(J_list_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Her har vi funnet endelige matriser, vektorer og verdier vi ønsker å bruke \n",
    "#på spiralen til slutt\n",
    "W_k_learned, b_k_learned, omega_learned, my_learned, features_1, labels_1, J_list1= trening1()\n",
    "Y_k_final = [features_1]\n",
    "J_list1_per_layer = [J(findZvalue(Y_k_final[-1], omega_learned, my_learned), labels_1 * 1)]\n",
    "for i in range(W_k_learned.shape[0]):\n",
    "    Y_next = findNextYMat(Y_k_final[-1], W_k_learned[i], b_k_learned[i])\n",
    "    Y_k_final.append(Y_next)\n",
    "    #J_list1_per_layer.append(J(findZvalue(Y_k_final[-1], omega_learned, my_learned), labels_1 * 1))\n",
    "#Har nå funnet alle Y også.\n",
    "Y_k_final = np.array(Y_k_final)\n",
    "\n",
    "\n",
    "#Definerer andre testsett:\n",
    "features_2, labels_2 = read_spiral_from_file('spiral_text_file2.txt')\n",
    "Y_k_final2 = [features_2]\n",
    "#J_list2_per_layer = [J(findZvalue(Y_k_final2[-1], omega_learned, my_learned), labels_2 * 1)]\n",
    "for i in range(W_k_learned.shape[0]):\n",
    "    Y_next2 = findNextYMat(Y_k_final2[-1], W_k_learned[i], b_k_learned[i])\n",
    "    Y_k_final2.append(Y_next2)\n",
    "    #J_list2_per_layer.append(J(findZvalue(Y_k_final2[-1], omega_learned, my_learned), labels_2 * 1))\n",
    "Y_k_final2 = np.array(Y_k_final2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nedenfor er funksjonene brukt i $trening$. $getRandomParam$ lager tilfeldige startverdier for vekter, bias, $\\omega$ og $\\mu$. Startverdiene er tatt fra den standarde normalfordelingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomParam(d=2, K=20):\n",
    "    w_k=np.random.randn(K,d,d)\n",
    "    b_k=np.random.randn(K,d)\n",
    "    omega = np.random.randn(d)\n",
    "    my = np.random.rand(1)\n",
    "    return w_k,b_k,omega, my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return(np.tanh(x))\n",
    "\n",
    "def sigma_diff(x):\n",
    "    return(1-np.tanh(x)**2)\n",
    "\n",
    "def eta(x):\n",
    "    x[x > 350] = 300\n",
    "    return(np.exp(x)/(np.exp(x)+1))\n",
    "    #return 1/2*(1+np.tanh(x/2))\n",
    "\n",
    "def eta_diff(x):\n",
    "    x[x > 350] = 300\n",
    "    return np.exp(x)/(np.exp(x) + 1)**2\n",
    "    #return 1/4*(1-np.tanh(x/2)**2)\n",
    "        \n",
    "#Hjelpefunskjon for å regne ut vektorproduktet V_1@V_2^T\n",
    "def makeMatrixFromVec(a, b):\n",
    "    return_matrix = np.zeros((len(a), len(b)))\n",
    "    for i in range(len(b)):\n",
    "        return_matrix[:, i] = b[i]*a\n",
    "    return(return_matrix)\n",
    "    \n",
    "def findNextYVec(Y_k, W_k, b_k, h):\n",
    "    vec_for_sigma = np.dot(W_k, Y_k) + b_k\n",
    "    sigma_vec = sigma(vec_for_sigma)\n",
    "    return(Y_k+h*sigma_vec)\n",
    "\n",
    "def findNextYMat(Y_k_mat, W_k, b_k, h):\n",
    "    numberOfColumns = Y_k_mat.shape[1]\n",
    "    nextYMat = np.zeros((Y_k_mat.shape[0], numberOfColumns))\n",
    "    for column in range(numberOfColumns):\n",
    "        Y_k = Y_k_mat[:, column]\n",
    "        nextYMat[:, column] = findNextYVec(Y_k, W_k, b_k, h)\n",
    "    return(np.array(nextYMat))\n",
    "\n",
    "def findZvalue(Y_k_mat, w_vec, my):\n",
    "    vec_for_eta = np.dot(w_vec, Y_k_mat) + my\n",
    "    return(eta(vec_for_eta))\n",
    "\n",
    "def findGradJ(Z_vec, W_K, Y_K, Y_end, w_vec, c_vec, my, b_K, h, K):\n",
    "    #Regner ut et produkt som går igjen for å spare noen utregninger\n",
    "    prod_to_re_use = eta_diff(np.dot(w_vec, Y_end)+my) \n",
    "    J_diff_my = np.dot(prod_to_re_use, Z_vec-c_vec)\n",
    "    #dJ/dw  = Y_K * [(Z-c)had*eta_diff(Y_K^T*w + my*1Vec]\n",
    "    #had* er hadamard-produktet, som bare er å gange sammen alle elementene for seg, 1Vec er en vektor fylt med enere\n",
    "    diff_my_vec_for_product = np.multiply(Z_vec - c_vec, prod_to_re_use)\n",
    "    J_diff_w = np.dot(Y_end, diff_my_vec_for_product)\n",
    "    #Definerer P_K = dJ/dY_K\n",
    "    #dJ/dY_K = w_vec * [(Z_vec - c_vec)had*eta_diff(Y_K^T * w_vec + my*Vec1)]^T\n",
    "    #Rekursivt:\n",
    "    #P_k-1: P_k + h*W_k-1^T*[sigma_diff(W_k-1*Y_k-1 + b_k-1)had*P_k)\n",
    "    P_K = makeMatrixFromVec(w_vec, np.multiply(Z_vec - c_vec, prod_to_re_use))\n",
    "    #Ønsker nå å samle opp for alle de deriverte k < K:\n",
    "    P_k_liste = [P_K]\n",
    "    #Ønsker å lage b_k som en matrise, b_k har samme dimensjon som en kolonne av WdotY, men den må være like lang\n",
    "    for i in range(K-1, -1, -1):\n",
    "        #Starter å indeksere fra toppen, fordi W_k og Y_k inneholder k < K\n",
    "        WdotY = np.dot(W_K[i], Y_K[i])\n",
    "        b_i_mat = np.array([np.array([b_K[i][j] for e in range(WdotY.shape[1])]) for j in range(WdotY.shape[0])])\n",
    "        matrix_for_sigma_diff =  WdotY + b_i_mat\n",
    "        matrix_for_product = np.multiply(sigma_diff(matrix_for_sigma_diff), P_k_liste[0])\n",
    "        P_i = P_k_liste[0] + h * np.dot(np.transpose(W_K[i]), matrix_for_product)\n",
    "        P_k_liste.insert(0, P_i)\n",
    "    J_diff_W_matrix = []\n",
    "    #dJ/dW_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*Y_k^T\n",
    "    J_diff_b_vec = []\n",
    "    #dJ/db_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*\n",
    "    for j in range(K):\n",
    "        W_jY_j = np.dot(W_K[j], Y_K[j])\n",
    "        b_j_mat = np.array([np.array([b_K[j][c] for e in range(W_jY_j.shape[1])]) for c in range(W_jY_j.shape[0])])\n",
    "        one_vector = np.full((W_jY_j.shape[1]), 1)\n",
    "        J_diff_W_matrix.append(h*np.dot(P_k_liste[j+1]*sigma_diff(W_jY_j + b_j_mat), np.transpose(Y_K[j])))\n",
    "        J_diff_b_vec.append(h*np.dot(P_k_liste[j+1]*eta_diff(W_jY_j + b_j_mat), one_vector))\n",
    "    return(J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(Z,c):\n",
    "    return 0.5*np.linalg.norm(Z-c)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funksjonene $newU$ og $adam$ optimerer parameterne henholdsvis for første og andre testproblem. $newU$ bruker \"plain vanilla gradient descent\", mens $adam$ bruker Adam-metoden for å oppdatere parameterne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newU(W_k,b_vec,w,my,tau,J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my):\n",
    "    W_k = W_k - np.multiply(J_diff_W_matrix,tau)\n",
    "    b_vec = b_vec - np.multiply(J_diff_b_vec, tau)\n",
    "    w = w - tau*J_diff_w\n",
    "    my = my -tau*J_diff_my\n",
    "    return W_k, b_vec,w,my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam2(m,v,g,j):\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    alpha = 0.01\n",
    "    epsilon = 1.0E-8\n",
    "\n",
    "    m = np.multiply(beta1,m) + np.multiply((1-beta1),g)\n",
    "    v = np.multiply(beta2,v) + np.multiply((1-beta2),np.multiply(g,g))\n",
    "    m_hat = np.multiply(m,1/(1-beta1**j))\n",
    "    v_hat = np.multiply(v,1/(1-beta2**j))\n",
    "    \n",
    "    J = np.multiply(alpha,np.multiply(m_hat,1/((np.sqrt(v_hat)+epsilon))))\n",
    "    \n",
    "    return m,v,J\n",
    "\n",
    "def getStartMandV(w,b,o,m):\n",
    "    mW = np.zeros_like(w)\n",
    "    mb = np.zeros_like(b)\n",
    "    mOmega = np.zeros_like(o)\n",
    "    mMy = np.zeros_like(m)\n",
    "\n",
    "    return mW,mb,mOmega,mMy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_function(Y_0, W_k, b_k, h):\n",
    "    Y_k = [Y_0]\n",
    "    for i in range(W_k.shape[0]):\n",
    "        Y_next = findNextYMat(Y_k[-1], W_k[i], b_k[i], h)\n",
    "        Y_k.append(Y_next)\n",
    "    return(Y_k)\n",
    "\n",
    "#Forward tar inn Y_0, og lager Y_k helt til K ved hjelp av de fire parameterne. Må ta inn de learned parameterne. \n",
    "#Forward function skal bruke parameterne som allerede er oppdaterte og lagret i minnet, men den skal bruke de på nye\n",
    "#datapunkter Y_0, og gå gjennom alle k helt til Y_K.\n",
    "\n",
    "#Last funtion tar inn den siste Y_K, og returnere Z for denne matrisen. \n",
    "    \n",
    "def last_function(Y_K_final, omega, my): #Tar inn Y_K, det siste laget. Altså Y_K final. Første paramter er grid\n",
    "    Z=findZvalue(Y_K_final, omega, my)\n",
    "    return Z  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_progression(Y, C):\n",
    "    '''\n",
    "    This function should make K+1 plots showing how, as the network progresses through its layers,\n",
    "    the datapoints are drawn apart in such a way that they can be separated by a straight line.\n",
    "    \n",
    "    Y: A K+1-by-I-by-2 matrix of the values for each data point in the training set in each layer.\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Y.\n",
    "    '''\n",
    "    for k in range(Y.shape[0]):\n",
    "        show_dots(Y[k,:,:],C.flatten())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_model(forward_function, Ys, W_k, b_k, h, C, n):\n",
    "    '''\n",
    "    Make a map that shows what part of the 2d plane is classified as belonging to which spiral arm.\n",
    "    Also plot the training data in Ys, C.\n",
    "    \n",
    "    forward_function: A function that takes one argument, an S-by-2 matrix of S datapoints, and\n",
    "        returns a vector of S classification values.\n",
    "        \n",
    "        Hint: This function will use the weights you have found, so you might want it to be a method on a\n",
    "        class called something like Network or Model.\n",
    "    Ys: An I-by-2 matrix. Corresponding to Y[0,:,:]\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Ys.\n",
    "    n: Number of test-points in each direction. This controls the resolution of the plot.\n",
    "    '''\n",
    "    grid, coordinates = get_discretization(Ys, n)\n",
    "\n",
    "    Z = forward_function(grid, W_k, b_k, h)\n",
    "    l = np.linspace(0,1,8)\n",
    "    l = np.array([shading(x) for x in l])\n",
    "\n",
    "    plot_contours(*coordinates, Z, l, Ys, C.flatten())\n",
    "\n",
    "\n",
    "def plot_separation(last_function, Ys, omega, my, C, n):\n",
    "    '''\n",
    "    Show how the training data is represented in the last layer. Also maps the rest of the possible points in the plane.\n",
    "    \n",
    "    last_function: A function that takes one argument, and S-by-2 matrix of S intermediate states in\n",
    "        the network, and retruns a vector of S classification values.\n",
    "        It should multiply by w, add μ and evaluate 𝜂.\n",
    "        \n",
    "        Hint: This function will use the weights you have found, so you might want it to be a method on a\n",
    "        class called something like Network or Model.\n",
    "    Ys:An I-by-2 matrix. Corresponding to Y[-1,:,:].\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Ys.\n",
    "    n: Number of test-points in each direction. This controls the resolution of the plot.\n",
    "    '''\n",
    "    grid, coordinates = get_discretization(Ys, n)\n",
    "\n",
    "    Z = last_function(grid, omega, my)\n",
    "    l = np.linspace(0,1,500)\n",
    "\n",
    "    plot_contours(*coordinates, Z, l, Ys, C.flatten())\n",
    "\n",
    "\n",
    "######## Internals\n",
    "\n",
    "\n",
    "def show_dots(positions, labels):\n",
    "    '''Visualize the output of get_data_spiral_2d'''\n",
    "    plt.scatter(x=positions[0,:], y=positions[1,:], s=1, c=labels, cmap='bwr')\n",
    "    plt.axis([-1.2, 1.2, -1.2, 1.2])\n",
    "    plt.axis('square')\n",
    "\n",
    "\n",
    "def plot_contours(box, xcoordinates, ycoordinates, Z, l, Ys, C1):\n",
    "    n = xcoordinates.size\n",
    "    plt.contourf(xcoordinates, ycoordinates, Z.reshape((n,n)), cmap='seismic', levels=l)\n",
    "    plt.contour(xcoordinates, ycoordinates, Z.reshape((n,n)), levels=1, colors='k')\n",
    "    plt.scatter(x=Ys[0,:], y=Ys[1,:], s=1, c=C1, cmap='bwr')\n",
    "    plt.axis(box)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_discretization(Ys, n):\n",
    "    xmin, xmax, ymin, ymax = get_box(Ys)\n",
    "    xcoordinates = np.linspace(xmin, xmax, n)\n",
    "    ycoordinates = np.linspace(ymin, ymax, n)\n",
    "    grid = get_grid(xcoordinates, ycoordinates)\n",
    "    coordinates = ([xmin, xmax, ymin, ymax], xcoordinates, ycoordinates)\n",
    "    return grid, coordinates\n",
    "\n",
    "\n",
    "def get_box(Ys):\n",
    "    xmin = min(Ys[0,:])\n",
    "    xmax = max(Ys[0,:])\n",
    "    xdelta = xmax-xmin\n",
    "    xmin -= 0.2*xdelta\n",
    "    xmax += 0.2*xdelta\n",
    "    ymin = min(Ys[1,:])\n",
    "    ymax = max(Ys[1,:])\n",
    "    ydelta = ymax-ymin\n",
    "    ymin -= 0.2*ydelta\n",
    "    ymax += 0.2*ydelta\n",
    "    return xmin, xmax, ymin, ymax\n",
    "\n",
    "    \n",
    "def get_grid(xcoordinates, ycoordinates):\n",
    "    xv, yv = np.meshgrid(xcoordinates, ycoordinates)\n",
    "    xs = xv.reshape(-1)\n",
    "    ys= yv.reshape(-1)\n",
    "    grid = np.stack([xs,ys])\n",
    "    return grid\n",
    "\n",
    "\n",
    "def shading(x):\n",
    "    return shading1(shading2(x))\n",
    "\n",
    "\n",
    "def shading1(x):\n",
    "    if x == 0.0:\n",
    "        return 0.0\n",
    "    return 0.5 * np.tanh(np.tan(x * np.pi + np.pi / 2.0)) + 0.5\n",
    "\n",
    "\n",
    "def shading2(x):\n",
    "    if x < 0.5:\n",
    "        return 0.5 - np.sqrt(0.25 - x**2)\n",
    "    else:\n",
    "        return 0.5 + np.sqrt(0.25 -(x-1.0)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Første testproblem: Punkter i planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success(z, int_labels):\n",
    "    #asanyarray tillater oss å sette typen til alle elementer i arrayen. Vi vil ha heltall.\n",
    "    z = np.asanyarray(np.around(z, 0), dtype = int)\n",
    "    sum = 0\n",
    "    for i in range(len(z)):\n",
    "        if z[i] == int_labels[i]:\n",
    "            sum += 1\n",
    "    return(sum/len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotJ(J_liste):\n",
    "    x_akse = np.arange(len(J_liste))\n",
    "    plt.scatter(x_akse, J_liste)\n",
    "    plt.figure(10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_1 = labels_1 * 1\n",
    "#C_2 = labels_2 * 1\n",
    "\n",
    "\n",
    "\n",
    "#plot_progression(Y_k_final, C_1)\n",
    "#plot_progression(Y_k_final2, C_2)\n",
    "\n",
    "\n",
    "\n",
    "#plotJ(J_list1)\n",
    "#plotJ(J_list_layer)\n",
    "#plotJ(J_list_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Andre testproblem: Siffergjenkjenning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z_vec2 = findZvalue(Y_k_final2[-1], omega_learned, my_learned)\n",
    "#Z_vec1 = findZvalue(Y_k_final[-1], omega_learned, my_learned)\n",
    "Z_vec_mnist = findZvalue(Y_k_mnist[-1], omega_mnist, my_mnist)\n",
    "\n",
    "#print(success(Z_vec2, C_2))\n",
    "#print(success(Z_vec1, C_1))\n",
    "print(success(Z_vec_mnist, C_vec))\n",
    "\n",
    "#Lager meg en test:\n",
    "W_k_test, b_k_test, omega_test, my_test = getRandomParam(28*28, 10)\n",
    "#Vi får svært store verdier, så normerer alle startmatrisene litt\n",
    "W_k_test = np.dot(W_k_test, 1/(28**2))\n",
    "omega_test = np.dot(omega_test, 1/(28**2))\n",
    "Y_k_test = [images]\n",
    "for i in range(W_k_test.shape[0]):\n",
    "    Y_next = findNextYMat(Y_k_mnist[-1], W_k_test[i], b_k_test[i])\n",
    "    Y_k_test.append(Y_next)\n",
    "Y_k_test = np.array(Y_k_test)\n",
    "Z_vec_test = findZvalue(Y_k_test[-1], omega_test, my_test)\n",
    "success(Z_vec_test, C_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spiral_to_file(filename = 'spiral_text_file.txt', n = 200):\n",
    "    features, labels = get_data_spiral_2d(n)\n",
    "    try:\n",
    "        file = open(filename, 'x')\n",
    "    except FileExistsError:\n",
    "        file = open(filename, 'w')\n",
    "    features_0 = ''\n",
    "    features_1 = ''\n",
    "    labels_str = ''\n",
    "    #Itererer gjennom nesten hele datasettet, fordi siste element skal håndteres litt annerledes\n",
    "    for n in range(len(features[0]) - 1):\n",
    "        features_0 += str(features[0][n]) + ', '\n",
    "        features_1 += str(features[1][n]) + ', '\n",
    "        labels_str += str(labels[n][0]) + ', '\n",
    "    features_0 += str(features[0][len(features[0]) - 1]) + '\\n'\n",
    "    features_1 += str(features[1][len(features[0]) - 1]) + '\\n'\n",
    "    labels_str += str(labels[len(features[0]) - 1][0]) + '\\n'\n",
    "    file.write(features_0)\n",
    "    file.write(features_1)\n",
    "    file.write(labels_str)\n",
    "    file.close()\n",
    "    \n",
    "def read_spiral_from_file(filename = 'spiral_text_file.txt'):\n",
    "    #Denne funksjonen leser en fil som er lagret på formatet fra write_spiral_to_file\n",
    "    file = open(filename, 'r')\n",
    "    #Vet at filen lagres med tre linjer\n",
    "    features_0 = file.readline()\n",
    "    features_0.strip()\n",
    "    features_list_0 = features_0.split(', ')\n",
    "    features_1 = file.readline()\n",
    "    features_1.strip()\n",
    "    features_list_1 = features_1.split(', ')\n",
    "    labels_str = file.readline()\n",
    "    labels_list = labels_str.split(', ')\n",
    "    for i in range(len(labels_list)):\n",
    "        features_list_0[i] = float(features_list_0[i])\n",
    "        features_list_1[i] = float(features_list_1[i])\n",
    "        if labels_list[i] == 'True':\n",
    "            labels_list[i] = True\n",
    "        else:\n",
    "            labels_list[i] = False\n",
    "    return(np.array([features_list_0, features_list_1]), np.array(labels_list))\n",
    "\n",
    "#write_spiral_to_file('spiral_text_file.txt', n = 1000)\n",
    "#write_spiral_to_file('spiral_text_file2.txt', n = 1000)\n",
    "#features, labels = read_spiral_from_file()\n",
    "#print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeParams(W_k, b_k, omega, my, filename = 'trainingParams.txt'):\n",
    "    try:\n",
    "        file = open(filename, 'x')\n",
    "    except FileExistsError:\n",
    "        file = open(filename, 'w')\n",
    "\n",
    "    Wk_str = \"\"\n",
    "    for W in W_k:\n",
    "        for w in W:\n",
    "            for i in w:\n",
    "                Wk_str += str(i) + ','\n",
    "    Wk_str += '\\n'\n",
    "\n",
    "    bk_str = \"\"\n",
    "    for B in b_k:\n",
    "        for b in B:\n",
    "            bk_str += str(b) + ','\n",
    "    bk_str += '\\n'\n",
    "\n",
    "    omega_str = \"\"\n",
    "    for o in omega:\n",
    "        omega_str += str(o) + ','\n",
    "    omega_str += '\\n'\n",
    "\n",
    "    my_str = str(my[0]) + '\\n'\n",
    "\n",
    "    file.write(Wk_str+bk_str+omega_str+my_str)\n",
    "    file.close()\n",
    "\n",
    "def readParams(K=20,d=2, filename = 'trainingParams.txt'):\n",
    "    try:\n",
    "        file = open(filename, 'r')\n",
    "    except FileExistsError:\n",
    "        print(\"Kunne ikke finne\",filename)\n",
    "\n",
    "    w_k = np.zeros((K, d, d))\n",
    "    b_k = np.zeros((K, d))\n",
    "    omega = np.zeros(d)\n",
    "    my = np.zeros(1)\n",
    "\n",
    "    W = file.readline().split(',')\n",
    "    B = file.readline().split(',')\n",
    "    O = file.readline().split(',')\n",
    "    M = file.readline()\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    for k in range(K):\n",
    "        for w in range(d):\n",
    "            for i in range(d):\n",
    "                w_k[k][w][i]= float(W[0])\n",
    "                W.pop(0)\n",
    "\n",
    "    for k in range(K):\n",
    "        for i in range(d):\n",
    "            b_k[k][i]=float(B[0])\n",
    "            B.pop(0)\n",
    "\n",
    "\n",
    "    for i in range(d):\n",
    "        omega[i] = float(O[i])\n",
    "\n",
    "    my[0] = float(M)\n",
    "\n",
    "    return w_k,b_k,omega,my\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
