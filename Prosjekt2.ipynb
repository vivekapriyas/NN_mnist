{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <center>\n",
    "        TMA4320 Prosjekt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formålet med prosjektet er å gi en introduksjon til maskinlæring, nærmere bestemt dyplæring og dype nevrale nettverk, ved egen implementering av algoritmene. \n",
    "Ideen er å trene dataprogrammet til å gjenkjenne bildeelementer i to ulike testproblemer. I det første testproblemet er problemstillingen forenklet til gjenkjenning av fargede datapunkt, mens i det andre testproblemet skal programmet kunne skille mellom to ulike håndskrevne sifre. \n",
    "Denne rapporten skal først presentere den grunneleggende algoritmen som benyttes i treningsfasen og hovedsaklig er lik for begge problemstillingene, før hver problemstilling blir framstilt i detalj.\n",
    "Valg av startparametre skal begrunnes og parametrene som ble funnet i treningsfasen skal presenteres. Deretter skal modellen med disse fikserte parametrene kjøres med nye data og resultatene bli lagt fram og diskutert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmen er delt inn i ulike funksjoner for å forenkle kodestrukturen. Først blir det laget fire tilfeldige parametere; K vektere $W_{k}$, K bias $b_{k}$, en vektor $\\omega$ og en skalar $\\mu$. $K$ er totalt antall lag i transformasjonen. Videre blir et bilde $Y_k$ transformert til det neste laget $k+1$ ved hjelp av en vekter, en bias og funksjonen $\\sigma (x)$. Når de  $I$ bildene har blitt transformert gjennom alle lagene blir hver av de projisert ned på en skalar $Z$ ved hjelp av $\\omega$, $\\mu$ og funksjonen $\\eta (x)$. Verdiene for hvert av de $I$ bildene i $Z$ blir sammenliknet med fasitverdiene i $c$, og denne differansen representeres i $J$. For å minimere $J$ finner funksjonen findGradJ de fire gradientene til $J$ med hensyn på de ulike parameterne. Deretter blir vekter og bias oppdatert ved hjelp av \"plain vanilla gradient descent\" for spiralen og Adam-metoden for siffergjenkjenning for å optimere parameterne. Parameterne blir også lagret i en tekstfil for hver transformasjon gjennom de $K$ lagene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30283779 -0.31533069]\n",
      "[1.86253299]\n",
      "[-0.11659648]\n",
      "[0.42991812]\n",
      "[1.8621834]\n",
      "[-2.57216958]\n",
      "[-0.1223136]\n",
      "[-0.02072939]\n",
      "[-0.00119516]\n",
      "[-4.01269982e-05]\n",
      "[-2.40395981e-06]\n",
      "[-1.8370084e-07]\n",
      "[-1.44147764e-08]\n",
      "[-1.13356997e-09]\n",
      "[-8.91587025e-11]\n",
      "[-7.01269759e-12]\n",
      "[-5.5157803e-13]\n",
      "[-4.33839255e-14]\n",
      "[-3.41232774e-15]\n",
      "[-2.68393891e-16]\n",
      "[-2.11103054e-17]\n",
      "[-1.66041408e-18]\n",
      "[-1.30598533e-19]\n",
      "[-1.02721224e-20]\n",
      "[-8.07945521e-22]\n",
      "[-6.35483045e-23]\n",
      "[-4.99834073e-24]\n",
      "[-3.93140466e-25]\n",
      "[-3.09221469e-26]\n",
      "[-2.43215657e-27]\n",
      "[-1.91299317e-28]\n",
      "[-1.50464938e-29]\n",
      "[-1.18346985e-30]\n",
      "[-9.30848687e-32]\n",
      "[-7.32151541e-33]\n",
      "[-5.758679e-34]\n",
      "[-4.52944261e-35]\n",
      "[-3.56259662e-36]\n",
      "[-2.80213169e-37]\n",
      "[-2.20399412e-38]\n",
      "[-1.73353383e-39]\n",
      "[-1.36349708e-40]\n",
      "[-1.07244765e-41]\n",
      "[-8.43525067e-43]\n",
      "[-6.63467851e-44]\n",
      "[-5.21845297e-45]\n",
      "[-4.10453217e-46]\n",
      "[-3.22838674e-47]\n",
      "[-2.5392616e-48]\n",
      "[-1.99723577e-49]\n",
      "[-1.57090971e-50]\n",
      "[-1.23558639e-51]\n",
      "[-9.71840527e-53]\n",
      "[-7.64393343e-54]\n",
      "[-6.0122743e-55]\n",
      "[-4.72890595e-56]\n",
      "[-3.71948291e-57]\n",
      "[-2.92552934e-58]\n",
      "[-2.30105155e-59]\n",
      "[-1.80987357e-60]\n",
      "[-1.42354149e-61]\n",
      "[-1.1196751e-62]\n",
      "[-8.80671432e-64]\n",
      "[-6.92685025e-65]\n",
      "[-5.4482583e-66]\n",
      "[-4.28528371e-67]\n",
      "[-3.3705554e-68]\n",
      "[-2.65108322e-69]\n",
      "[-2.08518816e-70]\n",
      "[-1.64008796e-71]\n",
      "[-1.28999798e-72]\n",
      "[-1.01463753e-73]\n",
      "[-7.98054979e-75]\n",
      "[-6.27703719e-76]\n",
      "[-4.93715307e-77]\n",
      "[-3.883278e-78]\n",
      "[-3.05436105e-79]\n",
      "[-2.40238309e-80]\n",
      "[-1.88957508e-81]\n",
      "[-1.48623007e-82]\n",
      "[-1.1689823e-83]\n",
      "[-9.19453614e-85]\n",
      "[-7.23188838e-86]\n",
      "[-5.68818359e-87]\n",
      "[-4.47399501e-88]\n",
      "[-3.51898475e-89]\n",
      "[-2.76782913e-90]\n",
      "[-2.17701372e-91]\n",
      "[-1.71231261e-92]\n",
      "[-1.3468057e-93]\n",
      "[-1.05931918e-94]\n",
      "[-8.33198975e-96]\n",
      "[-6.55345946e-97]\n",
      "[-5.15457078e-98]\n",
      "[-4.05428615e-99]\n",
      "[-3.18886613e-100]\n",
      "[-2.50817699e-101]\n",
      "[-1.97278642e-102]\n",
      "[-1.55167927e-103]\n",
      "[-1.22046084e-104]\n",
      "[-9.59943649e-106]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.48713114,  0.03314166],\n",
       "         [ 1.73831018,  1.02927005]],\n",
       " \n",
       "        [[ 0.3160861 ,  0.07752682],\n",
       "         [ 1.5908572 , -2.27479689]],\n",
       " \n",
       "        [[ 0.68743864,  0.22300783],\n",
       "         [-1.48891508, -1.52637237]]]), array([[ 0.77944991,  0.46808953],\n",
       "        [-0.97202455,  0.24786297],\n",
       "        [-0.03709105, -0.33566648]]), array([ 0.86836561, -0.06240252]), array([0.23874372]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trening1(n=100):\n",
    "    \n",
    "    features, labels = read_spiral_from_file()\n",
    "    W_k, b_k, omega, my = getRandomParam()\n",
    "    tau = 0.01\n",
    "    print(omega)\n",
    "    \n",
    "    c_vec = labels*1\n",
    "    Y_k = [features]\n",
    "       \n",
    "    for i in range(n):\n",
    "        for i in range(W_k.shape[0]):\n",
    "            Y_next = findNextYMat(Y_k[-1], W_k[i], b_k[i])\n",
    "            Y_k.append(Y_next)\n",
    "    \n",
    "        z_vec = findZvalue(Y_k[-1],omega,my)\n",
    "    \n",
    "    #Nå inneholder Y_k ALLE k, dvs at Y_end er med i Y_k, og må derfor skilles ut før Y_k settes inn i \n",
    "    #Gradientfunksjonen\n",
    "    \n",
    "        J_diff_W, J_diff_b, J_diff_omega, J_diff_my = findGradJ(z_vec,W_k,Y_k[:-1],Y_k[-1],omega,c_vec,my,b_k)\n",
    "        W_k, b_k, omega, my = U_jPlussEn(W_k,b_k,omega,my,tau,J_diff_W,J_diff_b,J_diff_omega,J_diff_my)\n",
    "    #print(W_k)\n",
    "    return(W_k, b_k, omega, my)\n",
    "    \n",
    "trening1()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager w_k og b_k\n",
    "\n",
    "def getRandomParam(d=2, K=3):\n",
    "    w_k=np.random.randn(K,d,d)\n",
    "    b_k=np.random.randn(K,d)\n",
    "    omega = np.random.randn(d)\n",
    "    my = np.random.rand(1)\n",
    "    return w_k,b_k,omega, my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.23840584  1.9993293   1.9993293 ]\n",
      " [ 0.03597242  1.9993293   1.9993293 ]]\n"
     ]
    }
   ],
   "source": [
    "h = 1\n",
    "#Definerer konstant for antall lag:\n",
    "K = 3\n",
    "\n",
    "#Finner Y_k+1\n",
    "#Trenger først sigma, aktiveringsfunksjonen\n",
    "def sigma(x):\n",
    "    return(np.tanh(x))\n",
    "#     Dersom vi heller vil bruke max(), nå må x kun være vektor, denne må utvides:\n",
    "#     Denne er brukt til å teste funksjonene\n",
    "#     if isinstance(x, (np.ndarray, list)):\n",
    "#         returliste = []\n",
    "#         for element in x:\n",
    "#             returliste.append(max(element, 0))\n",
    "#         return(np.array(returliste))\n",
    "#     else:\n",
    "#         return(max(0, x))\n",
    "\n",
    "#Sigma derivert analytisk\n",
    "def sigma_diff(x):\n",
    "    return(1-np.tanh(x)**2)\n",
    "\n",
    "def eta(x):\n",
    "    return(np.exp(x)/(np.exp(x)+1))\n",
    "\n",
    "#Analytisk løsning av derivasjon av eta\n",
    "def eta_diff(x):\n",
    "    return(np.exp(x)/(np.exp(x) + 1)**2)\n",
    "    \n",
    "def checkArray(array, string):\n",
    "    if isinstance(array, list):\n",
    "        return(np.array(array))\n",
    "    elif not isinstance(array, np.ndarray):\n",
    "        raise ValueError(string, \"was not an np.ndarray.\")\n",
    "        \n",
    "#Hjelpefunskjon for å regne ut vektorproduktet V_1@V_2^T\n",
    "#Denne vil altså returnere en matrise, ikke en skalar størrelse\n",
    "def makeMatrixFromVec(a, b):\n",
    "    return_matrix = np.zeros((len(a), len(b)))\n",
    "    for i in range(len(b)):\n",
    "        return_matrix[:, i] = b[i]*a\n",
    "    return(return_matrix)\n",
    "    \n",
    "def findNextYVec(Y_k, W_k, b_k):\n",
    "    #Denne funksjonen skal finne Y_k+1 = Y_k + h sigma(W_k * Y_k + b_k)\n",
    "    #Y er en matrise (dxI), W er en matrise (dxd) og b er en vektor\n",
    "    #Her er sigma en skalar funksjon som anvendes komponentvis på vektoren.\n",
    "    #All input skal være np.ndarrays, men b_k vil være den eneste som lager krøll\n",
    "    checkArray(b_k, 'b_k')\n",
    "    # Finner produktet W_k * Y_k og legger til b_k\n",
    "    vec_for_sigma = np.dot(W_k, Y_k) + b_k\n",
    "    #Anvender sigma elementvis\n",
    "    sigma_vec = sigma(vec_for_sigma)\n",
    "    #Avkommenter for å sjekke at sigma gjør som den skal\n",
    "    #print(vec_for_sigma)\n",
    "    #print(sigma_vec)\n",
    "    return(Y_k+h*sigma_vec)\n",
    "\n",
    "def findNextYMat(Y_k_mat, W_k, b_k):\n",
    "    #Shape[1] finner antall kolonner\n",
    "    #Shape[0] finner antall rader, dvs. samme som len()\n",
    "    numberOfColumns = Y_k_mat.shape[1]\n",
    "    nextYMat = np.array([np.array([0.0 for i in range(numberOfColumns)]) for e in range(Y_k_mat.shape[0])])\n",
    "    for column in range(numberOfColumns):\n",
    "        Y_k = Y_k_mat[:, column]\n",
    "        nextYMat[:, column] = findNextYVec(Y_k, W_k, b_k)\n",
    "    return(np.array(nextYMat))\n",
    "\n",
    "#Legger ved matrisene jeg har brukt for å sjekke at alt fungerer som det skal\n",
    "A = np.array([[1, 2], [2, 1]])\n",
    "Y_k_mat = np.array([np.array([-2, 1, 1]), np.array([1, 1, 1])])\n",
    "print(findNextYMat(Y_k_mat, A, np.array([1, 1])))\n",
    "#Her er altså b_k = [1, 1]\n",
    "\n",
    "#Hjelpefunksjon som vi strengt tatt definerer på nytt senere, men det er denne jeg har brukt i testene\n",
    "def findZvalue(Y_k_mat, w_vec, my):\n",
    "    #w og my er konstante mellom alle K-lag, men endres for for iterasjon\n",
    "    #Skal regne ut eta(Y_k^T * w + my * [1 for i in range(len(w))]\n",
    "    #n = len(Y_k_mat)\n",
    "    #d = len(Y_k_mat[0])\n",
    "    \n",
    "    #Y_trans = np.array([[Y_k_mat[i,j] for i in range(n)]for j in range(d)])\n",
    "    vec_for_eta = np.dot(w_vec, Y_k_mat) + my #np.array([my for i in range(Y_k_mat.shape[1])])\n",
    "    #Kan også regne ut:\n",
    "    #Y_T = np.transpose(Y_k_mat)\n",
    "    #vec_for_eta = np.dot(Y_T, w) + np.array([w for i in range(len(w))])\n",
    "    #print(vec_for_eta)\n",
    "    return(eta(vec_for_eta))\n",
    "\n",
    "def findGradJ(Z_vec, W_K, Y_K, Y_end, w_vec, c_vec, my, b_K):\n",
    "     #Til kodeoptimalisering - et produkt går igjen: eta_diff(Y_K^T * w_vec + my*Vec1)\n",
    "    prod_to_re_use = eta_diff(np.dot(w_vec, Y_end)+my) #np.array([my for i in range(len(Z_vec))]))\n",
    "    #print(\"Prod_to_re_use: \", prod_to_re_use)\n",
    "    #print(\"Z_vec-c_vec: \", Z_vec - c_vec)\n",
    "    #print(\"J_diff_my: \", np.dot(prod_to_re_use, Z_vec-c_vec))\n",
    "    #Dette kommer egentlig til slutt, men starter der:\n",
    "    #Z befinner seg inni U\n",
    "    J_diff_my = 0\n",
    "    for i in range(len(Z_vec)):\n",
    "        J_diff_my += (Z_vec[i]-c_vec[i])*eta_diff(np.dot(w_vec, Y_end[:, i])+my)\n",
    "    print(J_diff_my)\n",
    "    #J_diff_my sjekket for hånd!\n",
    "    #dJ/dw  = Y_K * [(Z-c)had*eta_diff(Y_K^T*w + my*1Vec]\n",
    "    #had* er hadamard-produktet, som bare er å gange sammen alle elementene for seg, 1Vec er en vektor fylt med enere\n",
    "    diff_my_vec_for_product = np.multiply(Z_vec - c_vec, prod_to_re_use)\n",
    "    #print(\"diff_my_vec_for_product: \", diff_my_vec_for_product)\n",
    "    #print(\"Y_end: \", Y_end)\n",
    "    #Sjekket for hånd!\n",
    "    J_diff_w = np.dot(Y_end, diff_my_vec_for_product)\n",
    "    #Definerer P_K = dJ/dY_K\n",
    "    #P_K er altså en matrise\n",
    "    #dJ/dY_K = w_vec * [(Z_vec - c_vec)had*eta_diff(Y_K^T * w_vec + my*Vec1)]^T      NB: Husk transponering\n",
    "    #Rekursivt:\n",
    "    #P_k-1: P_k + h*W_k-1^T*[sigma_diff(W_k-1*Y_k-1 + b_k-1)had*P_k)\n",
    "    P_K = makeMatrixFromVec(w_vec, np.multiply(Z_vec - c_vec, prod_to_re_use))\n",
    "    #Ønsker nå å samle opp for alle de deriverte k < K:\n",
    "    P_k_liste = [P_K]\n",
    "    #Ønsker å lage b_k som en matrise, b_k har samme dimensjon som en kolonne av WdotY, men den må være like lang\n",
    "    for i in range(K-1, -1, -1):\n",
    "        #Starter å indeksere fra toppen, fordi W_k og Y_k inneholder k < K\n",
    "        WdotY = np.dot(W_K[i], Y_K[i])\n",
    "        b_i_mat = np.array([np.array([b_K[i][j] for e in range(WdotY.shape[1])]) for j in range(WdotY.shape[0])])\n",
    "        matrix_for_sigma_diff =  WdotY + b_i_mat\n",
    "        matrix_for_product = np.multiply(sigma_diff(matrix_for_sigma_diff), P_k_liste[0])\n",
    "        P_i = P_k_liste[0] + h * np.dot(np.transpose(W_K[i]), matrix_for_product)\n",
    "        P_k_liste.insert(0, P_i)\n",
    "    #Har nå funnet alle P_k, og kan begynne å regne ut de deriverte.\n",
    "    J_diff_W_matrix = []\n",
    "    #dJ/dW_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*Y_k^T\n",
    "    J_diff_b_vec = []\n",
    "    #dJ/db_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*\n",
    "    for j in range(K):\n",
    "        W_jY_j = np.dot(W_K[j], Y_K[j])\n",
    "        b_j_mat = np.array([np.array([b_K[j][c] for e in range(W_jY_j.shape[1])]) for c in range(W_jY_j.shape[0])])\n",
    "        one_vector = np.array([1.0 for e in range(W_jY_j.shape[1])])\n",
    "        J_diff_W_matrix.append(h*np.dot(P_k_liste[j+1]*sigma_diff(W_jY_j + b_j_mat), np.transpose(Y_K[j])))\n",
    "        J_diff_b_vec.append(h*np.dot(P_k_liste[j+1]*eta_diff(W_jY_j + b_j_mat), one_vector))\n",
    "    return(J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager Z\n",
    "def n(x):\n",
    "    return (np.exp(x))/(np.exp(x)+1)\n",
    "\n",
    "def Z(Y_k, w, u, n):\n",
    "    vec=Y_k.transpose()@w + u*np.ones(((Y_k.transpose()@w).size), dtype=int)\n",
    "    return n(vec)\n",
    "\n",
    "#print(Z(Y_k,w,u,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lager J\n",
    "\n",
    "def J(Z,c):\n",
    "    return 0.5*np.linalg.norm(Z-c)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lager neste U, dvs. parametrene\n",
    "\n",
    "def U_jPlussEn(W_k,b_vec,w,my,tau,J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my):\n",
    "    W_k = W_k - np.multiply(J_diff_W_matrix,tau)\n",
    "    b_vec = b_vec - np.multiply(J_diff_b_vec, tau)\n",
    "    w = w - tau*J_diff_w\n",
    "    my = my -tau*J_diff_my\n",
    "    return W_k, b_vec,w,my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam descent\n",
    "\n",
    "                                                                                                                             \n",
    "def adam(m,v,j,J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my,W_k,b_vec,w,my):                                           \n",
    "    beta1 = 0.9                                                                                                              \n",
    "    beta2 = 0.999                                                                                                            \n",
    "    alfa = 0.01                                                                                                              \n",
    "    epsilon = 1E-8                                                                                                           \n",
    "                                                                                                                             \n",
    "    G = [J_diff_W_matrix,J_diff_b_vec,J_diff_w,J_diff_my]                                                                    \n",
    "    U = [W_k,b_vec,w,my]                                                                                                     \n",
    "                                                                                                                             \n",
    "    for i in range(len(G)):                                                                                                  \n",
    "                                                                                                                             \n",
    "        m = m + (1-beta1)*G[i]                                                                                               \n",
    "        v = v + (1-beta2)*(g[i]*g[i])                                                                                        \n",
    "                                                                                                                             \n",
    "        mj = m/(1-beta1**j)                                                                                                  \n",
    "        vj = v/(1-beta2**j)                                                                                                  \n",
    "                                                                                                                             \n",
    "        U[i] = U[i] - alfa*(mj/(np.sqrt(vj)+epsilon))                                                                        \n",
    "                                                                                                                             \n",
    "    return W_k,b_vec,w,my, m,v                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spiral_to_file(filename = 'spiral_text_file.txt'):\n",
    "    features, labels = get_data_spiral_2d()\n",
    "    try:\n",
    "        file = open(filename, 'x')\n",
    "    except FileExistsError:\n",
    "        file = open(filename, 'w')\n",
    "    features_0 = ''\n",
    "    features_1 = ''\n",
    "    labels_str = ''\n",
    "    #Itererer gjennom nesten hele datasettet, fordi siste element skal håndteres litt annerledes\n",
    "    for n in range(len(features[0]) - 1):\n",
    "        features_0 += str(features[0][n]) + ', '\n",
    "        features_1 += str(features[1][n]) + ', '\n",
    "        labels_str += str(labels[n][0]) + ', '\n",
    "    features_0 += str(features[0][len(features[0]) - 1]) + '\\n'\n",
    "    features_1 += str(features[1][len(features[0]) - 1]) + '\\n'\n",
    "    labels_str += str(labels[len(features[0]) - 1][0]) + '\\n'\n",
    "    print(features_0, features_1, labels_str)\n",
    "    file.write(features_0)\n",
    "    file.write(features_1)\n",
    "    file.write(labels_str)\n",
    "    file.close()\n",
    "    \n",
    "def read_spiral_from_file(filename = 'spiral_text_file.txt'):\n",
    "    #Denne funksjonen leser en fil som er lagret på formatet fra write_spiral_to_file\n",
    "    file = open(filename, 'r')\n",
    "    #Vet at filen lagres med tre linjer\n",
    "    features_0 = file.readline()\n",
    "    features_0.strip()\n",
    "    features_list_0 = features_0.split(', ')\n",
    "    features_1 = file.readline()\n",
    "    features_1.strip()\n",
    "    features_list_1 = features_1.split(', ')\n",
    "    labels_str = file.readline()\n",
    "    labels_list = labels_str.split(', ')\n",
    "    for i in range(len(labels_list)):\n",
    "        features_list_0[i] = float(features_list_0[i])\n",
    "        features_list_1[i] = float(features_list_1[i])\n",
    "        if labels_list[i] == 'True':\n",
    "            labels_list[i] = True\n",
    "        else:\n",
    "            labels_list[i] = False\n",
    "    return(np.array([features_list_0, features_list_1]), np.array(labels_list))\n",
    "\n",
    "#write_spiral_to_file()\n",
    "\n",
    "#features, labels = read_spiral_from_file()\n",
    "#print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inkluderte funksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_spiral_2d(n_samples=200):\n",
    "    '''Create \"observations\" for training.\n",
    "    \n",
    "    Creates n_samples dots on two intertwined spirals.\n",
    "    The dots are classified based on which spiral they belong to and\n",
    "    then fuzzed by perturbing the coordinates and permuting the ordering.'''\n",
    "    m1 = math.ceil(n_samples / 2)\n",
    "    m2 = n_samples - m1\n",
    "    \n",
    "    n_turns = 1.0\n",
    "    \n",
    "    phi1 = np.pi\n",
    "    d1 = make_spiral(m1, phi1, n_turns)\n",
    "\n",
    "    \n",
    "    phi2 = (phi1 + np.pi) % (2.0 * np.pi)\n",
    "    d2 = make_spiral(m2, phi2, n_turns)\n",
    "    \n",
    "    features = np.hstack((d1, d2))\n",
    "    labels = np.ones((n_samples,1), dtype='bool_')\n",
    "    labels[m1:] = False\n",
    "    \n",
    "    features = features + .05 * np.random.randn(*features.shape)\n",
    "    \n",
    "    indexes = np.random.permutation(n_samples)\n",
    "    features = features[:, indexes]\n",
    "    labels = labels[indexes]\n",
    "\n",
    "\n",
    "    return features, labels\n",
    "#print(get_data_spiral_2d())\n",
    "\n",
    "def make_spiral(m, phi, n_turns):\n",
    "    '''Makes points on a spiral\n",
    "    \n",
    "    This is a utility function for get_data_spiral_2d'''\n",
    "    r = np.linspace(0.1, 1.0, m)\n",
    "    a = np.linspace(0.1, 2.0 * np.pi * n_turns, m)\n",
    "    xs = r * np.cos(a + phi)\n",
    "    ys = r * np.sin(a + phi)\n",
    "    return np.stack([xs, ys])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This module contains three functions that can plot some aspects of the simple 2d-points-in-a-spiral problem.\n",
    "The functions can be used as is, without looking into their inner workings.\n",
    "You can also use them as inspiration for other ways of visualizing what your neural net does.\n",
    "'''\n",
    "def forward_function(Y_k_mat, w_vec, my):\n",
    "    vec_for_eta = np.dot(w_vec, Y_k_mat) + my\n",
    "    return(eta(vec_for_eta))\n",
    "    \n",
    "def last_function(Y_K, omega, mu): #Tar inn Y_K\n",
    "    vec_for_eta = np.dot(omega, Y_K) + my\n",
    "    return(eta(vec_for_eta))\n",
    "\n",
    "\n",
    "def plot_progression(Y, C):\n",
    "    '''\n",
    "    This function should make K+1 plots showing how, as the network progresses through its layers,\n",
    "    the datapoints are drawn apart in such a way that they can be separated by a straight line.\n",
    "    \n",
    "    Y: A K+1-by-I-by-2 matrix of the values for each data point in the training set in each layer.\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Y.\n",
    "    '''\n",
    "    for k in range(Y.shape[0]):\n",
    "        show_dots(Y[k,:,:],C.flatten())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_model(forward_function, Ys, C, n):\n",
    "    '''\n",
    "    Make a map that shows what part of the 2d plane is classified as belonging to which spiral arm.\n",
    "    Also plot the training data in Ys, C.\n",
    "    \n",
    "    forward_function: A function that takes one argument, an S-by-2 matrix of S datapoints, and\n",
    "        returns a vector of S classification values.\n",
    "        \n",
    "        Hint: This function will use the weights you have found, so you might want it to be a method on a\n",
    "        class called something like Network or Model.\n",
    "    Ys: An I-by-2 matrix. Corresponding to Y[0,:,:]\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Ys.\n",
    "    n: Number of test-points in each direction. This controls the resolution of the plot.\n",
    "    '''\n",
    "    grid, coordinates = get_discretization(Ys, n)\n",
    "\n",
    "    Z = forward_function(grid)\n",
    "    l = np.linspace(0,1,8)\n",
    "    l = np.array([shading(x) for x in l])\n",
    "\n",
    "    plot_contours(*coordinates, Z, l, Ys, C.flatten())\n",
    "\n",
    "\n",
    "def plot_separation(last_function, Ys, C, n):\n",
    "    '''\n",
    "    Show how the training data is represented in the last layer. Also maps the rest of the possible points in the plane.\n",
    "    \n",
    "    last_function: A function that takes one argument, and S-by-2 matrix of S intermediate states in\n",
    "        the network, and retruns a vector of S classification values.\n",
    "        It should multiply by w, add μ and evaluate 𝜂.\n",
    "        \n",
    "        Hint: This function will use the weights you have found, so you might want it to be a method on a\n",
    "        class called something like Network or Model.\n",
    "    Ys:An I-by-2 matrix. Corresponding to Y[-1,:,:].\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Ys.\n",
    "    n: Number of test-points in each direction. This controls the resolution of the plot.\n",
    "    '''\n",
    "    grid, coordinates = get_discretization(Ys, n)\n",
    "\n",
    "    Z = last_function(grid)\n",
    "    l = np.linspace(0,1,500)\n",
    "\n",
    "    plot_contours(*coordinates, Z, l, Ys, C.flatten())\n",
    "\n",
    "\n",
    "######## Internals\n",
    "\n",
    "\n",
    "def show_dots(positions, labels):\n",
    "    '''Visualize the output of get_data_spiral_2d'''\n",
    "    plt.scatter(x=positions[0,:], y=positions[1,:], s=1, c=labels, cmap='bwr')\n",
    "    plt.axis([-1.2, 1.2, -1.2, 1.2])\n",
    "    plt.axis('square')\n",
    "\n",
    "\n",
    "def plot_contours(box, xcoordinates, ycoordinates, Z, l, Ys, C1):\n",
    "    n = xcoordinates.size\n",
    "    plt.contourf(xcoordinates, ycoordinates, Z.reshape((n,n)), cmap='seismic', levels=l)\n",
    "    plt.contour(xcoordinates, ycoordinates, Z.reshape((n,n)), levels=1, colors='k')\n",
    "    plt.scatter(x=Ys[0,:], y=Ys[1,:], s=1, c=C1, cmap='bwr')\n",
    "    plt.axis(box)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_discretization(Ys, n):\n",
    "    xmin, xmax, ymin, ymax = get_box(Ys)\n",
    "    xcoordinates = np.linspace(xmin, xmax, n)\n",
    "    ycoordinates = np.linspace(ymin, ymax, n)\n",
    "    grid = get_grid(xcoordinates, ycoordinates)\n",
    "    coordinates = ([xmin, xmax, ymin, ymax], xcoordinates, ycoordinates)\n",
    "    return grid, coordinates\n",
    "\n",
    "\n",
    "def get_box(Ys):\n",
    "    xmin = min(Ys[0,:])\n",
    "    xmax = max(Ys[0,:])\n",
    "    xdelta = xmax-xmin\n",
    "    xmin -= 0.2*xdelta\n",
    "    xmax += 0.2*xdelta\n",
    "    ymin = min(Ys[1,:])\n",
    "    ymax = max(Ys[1,:])\n",
    "    ydelta = ymax-ymin\n",
    "    ymin -= 0.2*ydelta\n",
    "    ymax += 0.2*ydelta\n",
    "    return xmin, xmax, ymin, ymax\n",
    "\n",
    "    \n",
    "def get_grid(xcoordinates, ycoordinates):\n",
    "    xv, yv = np.meshgrid(xcoordinates, ycoordinates)\n",
    "    xs = xv.reshape(-1)\n",
    "    ys= yv.reshape(-1)\n",
    "    grid = np.stack([xs,ys])\n",
    "    return grid\n",
    "\n",
    "\n",
    "def shading(x):\n",
    "    return shading1(shading2(x))\n",
    "\n",
    "\n",
    "def shading1(x):\n",
    "    if x == 0.0:\n",
    "        return 0.0\n",
    "    return 0.5 * np.tanh(np.tan(x * np.pi + np.pi / 2.0)) + 0.5\n",
    "\n",
    "\n",
    "def shading2(x):\n",
    "    if x < 0.5:\n",
    "        return 0.5 - np.sqrt(0.25 - x**2)\n",
    "    else:\n",
    "        return 0.5 + np.sqrt(0.25 -(x-1.0)**2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
