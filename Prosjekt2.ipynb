{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <center>\n",
    "        TMA4320 Prosjekt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form친let med prosjektet er 친 gi en introduksjon til maskinl칝ring, n칝rmere bestemt dypl칝ring og dype nevrale nettverk, ved egen implementering av algoritmene. \n",
    "Ideen er 친 trene dataprogrammet til 친 gjenkjenne bildeelementer i to ulike testproblemer. I det f칮rste testproblemet er problemstillingen forenklet til gjenkjenning av fargede datapunkt, mens i det andre testproblemet skal programmet kunne skille mellom to ulike h친ndskrevne sifre. \n",
    "Denne rapporten skal f칮rst presentere den grunneleggende algoritmen som benyttes i treningsfasen og hovedsaklig er lik for begge problemstillingene, f칮r hver problemstilling blir framstilt i detalj.\n",
    "Valg av startparametre skal begrunnes og parametrene som ble funnet i treningsfasen skal presenteres. Deretter skal modellen med disse fikserte parametrene kj칮res med nye data og resultatene bli lagt fram og diskutert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmen er delt inn i ulike funksjoner for 친 forenkle kodestrukturen. F칮rst blir det laget fire tilfeldige parametere; K vektere $W_{k}$, K bias $b_{k}$, en vektor $\\omega$ og en skalar $\\mu$. $K$ er totalt antall lag i transformasjonen. Videre blir et bilde $Y_k$ transformert til det neste laget $k+1$ ved hjelp av en vekter, en bias og funksjonen $\\sigma (x)$. N친r de  $I$ bildene har blitt transformert gjennom alle lagene blir hver av de projisert ned p친 en skalar $Z$ ved hjelp av $\\omega$, $\\mu$ og funksjonen $\\eta (x)$. Verdiene for hvert av de $I$ bildene i $Z$ blir sammenliknet med fasitverdiene i $c$, og denne differansen representeres i $J$. For 친 minimere $J$ finner funksjonen findGradJ de fire gradientene til $J$ med hensyn p친 de ulike parameterne. Deretter blir vekter og bias oppdatert ved hjelp av \"plain vanilla gradient descent\" for spiralen og Adam-metoden for siffergjenkjenning for 친 optimere parameterne. Parameterne blir ogs친 lagret i en tekstfil for hver transformasjon gjennom de $K$ lagene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trening1(n=1000):\n",
    "    \n",
    "    features, labels = read_spiral_from_file()\n",
    "    W_k, b_k, omega, my = getRandomParam(2, K)\n",
    "    tau = 0.01\n",
    "    \n",
    "    c_vec = labels*1\n",
    "    Y_k = [features]\n",
    "       \n",
    "    for i in range(n):\n",
    "        Y_k = [features]\n",
    "        for i in range(W_k.shape[0]):\n",
    "            Y_next = findNextYMat(Y_k[-1], W_k[i], b_k[i])\n",
    "            Y_k.append(Y_next)\n",
    "    \n",
    "        z_vec = findZvalue(Y_k[-1],omega,my)\n",
    "    \n",
    "    #N친 inneholder Y_k ALLE k, dvs at Y_end er med i Y_k, og m친 derfor skilles ut f칮r Y_k settes inn i \n",
    "    #Gradientfunksjonen\n",
    "    \n",
    "        J_diff_W, J_diff_b, J_diff_omega, J_diff_my = findGradJ(z_vec,W_k,Y_k[:-1],Y_k[-1],omega,c_vec,my,b_k)\n",
    "        W_k, b_k, omega, my = U_jPlussEn(W_k,b_k,omega,my,tau,J_diff_W,J_diff_b,J_diff_omega,J_diff_my)\n",
    "    #print(W_k)\n",
    "    return(W_k, b_k, omega, my, features, labels)\n",
    "\n",
    "#Her har vi funnet endelige matriser, vektorer og verdier vi 칮nsker 친 bruke \n",
    "#p친 spiralen til slutt\n",
    "W_k_learned, b_k_learned, omega_learned, my_learned, features_1, labels_1 = trening1()\n",
    "Y_k_final = [features_1]\n",
    "J_list1 = [J(findZvalue(Y_k_final[-1], omega_learned, my_learned), labels_1 * 1)]\n",
    "for i in range(W_k_learned.shape[0]):\n",
    "    Y_next = findNextYMat(Y_k_final[-1], W_k_learned[i], b_k_learned[i])\n",
    "    Y_k_final.append(Y_next)\n",
    "    J_list1.append(J(findZvalue(Y_k_final[-1], omega_learned, my_learned), labels_1 * 1))\n",
    "#Har n친 funnet alle Y ogs친.\n",
    "Y_k_final = np.array(Y_k_final)\n",
    "\n",
    "\n",
    "#Definerer andre testsett:\n",
    "features_2, labels_2 = read_spiral_from_file('spiral_text_file2.txt')\n",
    "Y_k_final2 = [features_2]\n",
    "J_list2 = [J(findZvalue(Y_k_final2[-1], omega_learned, my_learned), labels_2 * 1)]\n",
    "for i in range(W_k_learned.shape[0]):\n",
    "    Y_next2 = findNextYMat(Y_k_final2[-1], W_k_learned[i], b_k_learned[i])\n",
    "    Y_k_final2.append(Y_next2)\n",
    "    J_list2.append(J(findZvalue(Y_k_final2[-1], omega_learned, my_learned), labels_2 * 1))\n",
    "Y_k_final2 = np.array(Y_k_final2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import load_mnist\n",
    "\n",
    "Y_k, labels = load_mnist() #Images er Y_k\n",
    "\n",
    "def MNIST(n):\n",
    "    W_k, b_k, omega, my = getRandomParam(28, K)\n",
    "    tau = 0.01\n",
    "    c_vec = labels*1\n",
    "       \n",
    "    for i in range(n):\n",
    "        Y_k = [features]\n",
    "        for i in range(W_k.shape[0]):\n",
    "            Y_next = findNextYMat(Y_k[-1], W_k[i], b_k[i])\n",
    "            Y_k.append(Y_next)\n",
    "    \n",
    "        z_vec = findZvalue(Y_k[-1],omega,my)\n",
    "    \n",
    "        J_diff_W, J_diff_b, J_diff_omega, J_diff_my = findGradJ(z_vec,W_k,Y_k[:-1],Y_k[-1],omega,c_vec,my,b_k)\n",
    "        W_k, b_k, omega, my = adam(0,0,J_diff_W_matrix,J_diff_b_vec,J_diff_omega,J_diff_my,W_k,b_k,omega,my)\n",
    "    return(W_k, b_k, omega, my, features, labels)\n",
    "\n",
    "W_k_learned, b_k_learned, omega_learned, my_learned, features_1, labels_1 = MNIST()\n",
    "Y_k_final = [features_1]\n",
    "J_list1 = [J(findZvalue(Y_k_final[-1], omega_learned, my_learned), labels_1 * 1)]\n",
    "for i in range(W_k_learned.shape[0]):\n",
    "    Y_next = findNextYMat(Y_k_final[-1], W_k_learned[i], b_k_learned[i])\n",
    "    Y_k_final.append(Y_next)\n",
    "    J_list1.append(J(findZvalue(Y_k_final[-1], omega_learned, my_learned), labels_1 * 1))\n",
    "Y_k_final = np.array(Y_k_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager w_k og b_k\n",
    "def getRandomParam(d=2, K=20):\n",
    "    w_k=np.random.randn(K,d,d)\n",
    "    b_k=np.random.randn(K,d)\n",
    "    omega = np.random.randn(d)\n",
    "    my = np.random.rand(1)\n",
    "    return w_k,b_k,omega, my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1\n",
    "#Definerer konstant for antall lag:\n",
    "K = 20\n",
    "\n",
    "#Finner Y_k+1\n",
    "#Trenger f칮rst sigma, aktiveringsfunksjonen\n",
    "def sigma(x):\n",
    "    return(np.tanh(x))\n",
    "#     Dersom vi heller vil bruke max(), n친 m친 x kun v칝re vektor, denne m친 utvides:\n",
    "#     Denne er brukt til 친 teste funksjonene\n",
    "#     if isinstance(x, (np.ndarray, list)):\n",
    "#         returliste = []\n",
    "#         for element in x:\n",
    "#             returliste.append(max(element, 0))\n",
    "#         return(np.array(returliste))\n",
    "#     else:\n",
    "#         return(max(0, x))\n",
    "\n",
    "#Sigma derivert analytisk\n",
    "def sigma_diff(x):\n",
    "    return(1-np.tanh(x)**2)\n",
    "\n",
    "def eta(x):\n",
    "    return(np.exp(x)/(np.exp(x)+1))\n",
    "\n",
    "#Analytisk l칮sning av derivasjon av eta\n",
    "def eta_diff(x):\n",
    "    return(np.exp(x)/(np.exp(x) + 1)**2)\n",
    "    \n",
    "def checkArray(array, string):\n",
    "    if isinstance(array, list):\n",
    "        return(np.array(array))\n",
    "    elif not isinstance(array, np.ndarray):\n",
    "        raise ValueError(string, \"was not an np.ndarray.\")\n",
    "        \n",
    "#Hjelpefunskjon for 친 regne ut vektorproduktet V_1@V_2^T\n",
    "#Denne vil alts친 returnere en matrise, ikke en skalar st칮rrelse\n",
    "def makeMatrixFromVec(a, b):\n",
    "    return_matrix = np.zeros((len(a), len(b)))\n",
    "    for i in range(len(b)):\n",
    "        return_matrix[:, i] = b[i]*a\n",
    "    return(return_matrix)\n",
    "    \n",
    "def findNextYVec(Y_k, W_k, b_k):\n",
    "    #Denne funksjonen skal finne Y_k+1 = Y_k + h sigma(W_k * Y_k + b_k)\n",
    "    #Y er en matrise (dxI), W er en matrise (dxd) og b er en vektor\n",
    "    #Her er sigma en skalar funksjon som anvendes komponentvis p친 vektoren.\n",
    "    #All input skal v칝re np.ndarrays, men b_k vil v칝re den eneste som lager kr칮ll\n",
    "    checkArray(b_k, 'b_k')\n",
    "    # Finner produktet W_k * Y_k og legger til b_k\n",
    "    vec_for_sigma = np.dot(W_k, Y_k) + b_k\n",
    "    #Anvender sigma elementvis\n",
    "    sigma_vec = sigma(vec_for_sigma)\n",
    "    #Avkommenter for 친 sjekke at sigma gj칮r som den skal\n",
    "    #print(vec_for_sigma)\n",
    "    #print(sigma_vec)\n",
    "    return(Y_k+h*sigma_vec)\n",
    "\n",
    "def findNextYMat(Y_k_mat, W_k, b_k):\n",
    "    #Shape[1] finner antall kolonner\n",
    "    #Shape[0] finner antall rader, dvs. samme som len()\n",
    "    numberOfColumns = Y_k_mat.shape[1]\n",
    "    nextYMat = np.array([np.array([0.0 for i in range(numberOfColumns)]) for e in range(Y_k_mat.shape[0])])\n",
    "    for column in range(numberOfColumns):\n",
    "        Y_k = Y_k_mat[:, column]\n",
    "        nextYMat[:, column] = findNextYVec(Y_k, W_k, b_k)\n",
    "    return(np.array(nextYMat))\n",
    "\n",
    "#Legger ved matrisene jeg har brukt for 친 sjekke at alt fungerer som det skal\n",
    "A = np.array([[1, 2], [2, 1]])\n",
    "Y_k_mat = np.array([np.array([-2, 1, 1]), np.array([1, 1, 1])])\n",
    "print(findNextYMat(Y_k_mat, A, np.array([1, 1])))\n",
    "#Her er alts친 b_k = [1, 1]\n",
    "\n",
    "#Hjelpefunksjon som vi strengt tatt definerer p친 nytt senere, men det er denne jeg har brukt i testene\n",
    "def findZvalue(Y_k_mat, w_vec, my):\n",
    "    #w og my er konstante mellom alle K-lag, men endres for for iterasjon\n",
    "    #Skal regne ut eta(Y_k^T * w + my * [1 for i in range(len(w))]\n",
    "    #n = len(Y_k_mat)\n",
    "    #d = len(Y_k_mat[0])\n",
    "    \n",
    "    #Y_trans = np.array([[Y_k_mat[i,j] for i in range(n)]for j in range(d)])\n",
    "    vec_for_eta = np.dot(w_vec, Y_k_mat) + my #np.array([my for i in range(Y_k_mat.shape[1])])\n",
    "    #Kan ogs친 regne ut:\n",
    "    #Y_T = np.transpose(Y_k_mat)\n",
    "    #vec_for_eta = np.dot(Y_T, w) + np.array([w for i in range(len(w))])\n",
    "    #print(vec_for_eta)\n",
    "    return(eta(vec_for_eta))\n",
    "\n",
    "def findGradJ(Z_vec, W_K, Y_K, Y_end, w_vec, c_vec, my, b_K):\n",
    "     #Til kodeoptimalisering - et produkt g친r igjen: eta_diff(Y_K^T * w_vec + my*Vec1)\n",
    "    prod_to_re_use = eta_diff(np.dot(w_vec, Y_end)+my) #np.array([my for i in range(len(Z_vec))]))\n",
    "    #Dette kommer egentlig til slutt, men starter der:\n",
    "    J_diff_my = 0\n",
    "    for i in range(len(Z_vec)):\n",
    "        J_diff_my += (Z_vec[i]-c_vec[i])*eta_diff(np.dot(w_vec, Y_end[:, i])+my)\n",
    "    #dJ/dw  = Y_K * [(Z-c)had*eta_diff(Y_K^T*w + my*1Vec]\n",
    "    #had* er hadamard-produktet, som bare er 친 gange sammen alle elementene for seg, 1Vec er en vektor fylt med enere\n",
    "    diff_my_vec_for_product = np.multiply(Z_vec - c_vec, prod_to_re_use)\n",
    "    J_diff_w = np.dot(Y_end, diff_my_vec_for_product)\n",
    "    #Definerer P_K = dJ/dY_K\n",
    "    #P_K er alts친 en matrise\n",
    "    #dJ/dY_K = w_vec * [(Z_vec - c_vec)had*eta_diff(Y_K^T * w_vec + my*Vec1)]^T      NB: Husk transponering\n",
    "    #Rekursivt:\n",
    "    #P_k-1: P_k + h*W_k-1^T*[sigma_diff(W_k-1*Y_k-1 + b_k-1)had*P_k)\n",
    "    P_K = makeMatrixFromVec(w_vec, np.multiply(Z_vec - c_vec, prod_to_re_use))\n",
    "    #칒nsker n친 친 samle opp for alle de deriverte k < K:\n",
    "    P_k_liste = [P_K]\n",
    "    #칒nsker 친 lage b_k som en matrise, b_k har samme dimensjon som en kolonne av WdotY, men den m친 v칝re like lang\n",
    "    for i in range(K-1, -1, -1):\n",
    "        #Starter 친 indeksere fra toppen, fordi W_k og Y_k inneholder k < K\n",
    "        WdotY = np.dot(W_K[i], Y_K[i])\n",
    "        b_i_mat = np.array([np.array([b_K[i][j] for e in range(WdotY.shape[1])]) for j in range(WdotY.shape[0])])\n",
    "        matrix_for_sigma_diff =  WdotY + b_i_mat\n",
    "        matrix_for_product = np.multiply(sigma_diff(matrix_for_sigma_diff), P_k_liste[0])\n",
    "        P_i = P_k_liste[0] + h * np.dot(np.transpose(W_K[i]), matrix_for_product)\n",
    "        P_k_liste.insert(0, P_i)\n",
    "    #Har n친 funnet alle P_k, og kan begynne 친 regne ut de deriverte.\n",
    "    J_diff_W_matrix = []\n",
    "    #dJ/dW_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*Y_k^T\n",
    "    J_diff_b_vec = []\n",
    "    #dJ/db_k = h*[P_k+1 *had sigma_diff(W_k*Y_k + b_k)]*\n",
    "    for j in range(K):\n",
    "        W_jY_j = np.dot(W_K[j], Y_K[j])\n",
    "        b_j_mat = np.array([np.array([b_K[j][c] for e in range(W_jY_j.shape[1])]) for c in range(W_jY_j.shape[0])])\n",
    "        one_vector = np.array([1.0 for e in range(W_jY_j.shape[1])])\n",
    "        J_diff_W_matrix.append(h*np.dot(P_k_liste[j+1]*sigma_diff(W_jY_j + b_j_mat), np.transpose(Y_K[j])))\n",
    "        J_diff_b_vec.append(h*np.dot(P_k_liste[j+1]*eta_diff(W_jY_j + b_j_mat), one_vector))\n",
    "    return(J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager Z\n",
    "def n(x):\n",
    "    return (np.exp(x))/(np.exp(x)+1)\n",
    "\n",
    "def Z(Y_k, w, u, n):\n",
    "    vec=Y_k.transpose()@w + u*np.ones(((Y_k.transpose()@w).size), dtype=int)\n",
    "    return n(vec)\n",
    "\n",
    "#print(Z(Y_k,w,u,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lager J\n",
    "\n",
    "def J(Z,c):\n",
    "    return 0.5*np.linalg.norm(Z-c)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lager neste U, dvs. parametrene\n",
    "\n",
    "def U_jPlussEn(W_k,b_vec,w,my,tau,J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my):\n",
    "    W_k = W_k - np.multiply(J_diff_W_matrix,tau)\n",
    "    b_vec = b_vec - np.multiply(J_diff_b_vec, tau)\n",
    "    w = w - tau*J_diff_w\n",
    "    my = my -tau*J_diff_my\n",
    "    return W_k, b_vec,w,my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam descent\n",
    "\n",
    "                                                                                                                             \n",
    "def adam(m,v,j,J_diff_W_matrix, J_diff_b_vec, J_diff_w, J_diff_my,W_k,b_vec,w,my):                                           \n",
    "    beta1 = 0.9                                                                                                              \n",
    "    beta2 = 0.999                                                                                                            \n",
    "    alfa = 0.01                                                                                                              \n",
    "    epsilon = 1E-8                                                                                                           \n",
    "                                                                                                                             \n",
    "    G = [J_diff_W_matrix,J_diff_b_vec,J_diff_w,J_diff_my]                                                                    \n",
    "    U = [W_k,b_vec,w,my]                                                                                                     \n",
    "                                                                                                                             \n",
    "    for i in range(len(G)):                                                                                                  \n",
    "                                                                                                                             \n",
    "        m = m + (1-beta1)*G[i]                                                                                               \n",
    "        v = v + (1-beta2)*(g[i]*g[i])                                                                                        \n",
    "                                                                                                                             \n",
    "        mj = m/(1-beta1**j)                                                                                                  \n",
    "        vj = v/(1-beta2**j)                                                                                                  \n",
    "                                                                                                                             \n",
    "        U[i] = U[i] - alfa*(mj/(np.sqrt(vj)+epsilon))                                                                        \n",
    "                                                                                                                             \n",
    "    return W_k,b_vec,w,my, m,v                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spiral_to_file(filename = 'spiral_text_file.txt'):\n",
    "    features, labels = get_data_spiral_2d()\n",
    "    try:\n",
    "        file = open(filename, 'x')\n",
    "    except FileExistsError:\n",
    "        file = open(filename, 'w')\n",
    "    features_0 = ''\n",
    "    features_1 = ''\n",
    "    labels_str = ''\n",
    "    #Itererer gjennom nesten hele datasettet, fordi siste element skal h친ndteres litt annerledes\n",
    "    for n in range(len(features[0]) - 1):\n",
    "        features_0 += str(features[0][n]) + ', '\n",
    "        features_1 += str(features[1][n]) + ', '\n",
    "        labels_str += str(labels[n][0]) + ', '\n",
    "    features_0 += str(features[0][len(features[0]) - 1]) + '\\n'\n",
    "    features_1 += str(features[1][len(features[0]) - 1]) + '\\n'\n",
    "    labels_str += str(labels[len(features[0]) - 1][0]) + '\\n'\n",
    "    print(features_0, features_1, labels_str)\n",
    "    file.write(features_0)\n",
    "    file.write(features_1)\n",
    "    file.write(labels_str)\n",
    "    file.close()\n",
    "    \n",
    "def read_spiral_from_file(filename = 'spiral_text_file.txt'):\n",
    "    #Denne funksjonen leser en fil som er lagret p친 formatet fra write_spiral_to_file\n",
    "    file = open(filename, 'r')\n",
    "    #Vet at filen lagres med tre linjer\n",
    "    features_0 = file.readline()\n",
    "    features_0.strip()\n",
    "    features_list_0 = features_0.split(', ')\n",
    "    features_1 = file.readline()\n",
    "    features_1.strip()\n",
    "    features_list_1 = features_1.split(', ')\n",
    "    labels_str = file.readline()\n",
    "    labels_list = labels_str.split(', ')\n",
    "    for i in range(len(labels_list)):\n",
    "        features_list_0[i] = float(features_list_0[i])\n",
    "        features_list_1[i] = float(features_list_1[i])\n",
    "        if labels_list[i] == 'True':\n",
    "            labels_list[i] = True\n",
    "        else:\n",
    "            labels_list[i] = False\n",
    "    return(np.array([features_list_0, features_list_1]), np.array(labels_list))\n",
    "\n",
    "#write_spiral_to_file('spiral_text_file2.txt')\n",
    "\n",
    "#features, labels = read_spiral_from_file()\n",
    "#print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inkluderte funksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_spiral_2d(n_samples=200):\n",
    "    '''Create \"observations\" for training.\n",
    "    \n",
    "    Creates n_samples dots on two intertwined spirals.\n",
    "    The dots are classified based on which spiral they belong to and\n",
    "    then fuzzed by perturbing the coordinates and permuting the ordering.'''\n",
    "    m1 = math.ceil(n_samples / 2)\n",
    "    m2 = n_samples - m1\n",
    "    \n",
    "    n_turns = 1.0\n",
    "    \n",
    "    phi1 = np.pi\n",
    "    d1 = make_spiral(m1, phi1, n_turns)\n",
    "\n",
    "    \n",
    "    phi2 = (phi1 + np.pi) % (2.0 * np.pi)\n",
    "    d2 = make_spiral(m2, phi2, n_turns)\n",
    "    \n",
    "    features = np.hstack((d1, d2))\n",
    "    labels = np.ones((n_samples,1), dtype='bool_')\n",
    "    labels[m1:] = False\n",
    "    \n",
    "    features = features + .05 * np.random.randn(*features.shape)\n",
    "    \n",
    "    indexes = np.random.permutation(n_samples)\n",
    "    features = features[:, indexes]\n",
    "    labels = labels[indexes]\n",
    "\n",
    "\n",
    "    return features, labels\n",
    "#print(get_data_spiral_2d())\n",
    "\n",
    "def make_spiral(m, phi, n_turns):\n",
    "    '''Makes points on a spiral\n",
    "    \n",
    "    This is a utility function for get_data_spiral_2d'''\n",
    "    r = np.linspace(0.1, 1.0, m)\n",
    "    a = np.linspace(0.1, 2.0 * np.pi * n_turns, m)\n",
    "    xs = r * np.cos(a + phi)\n",
    "    ys = r * np.sin(a + phi)\n",
    "    return np.stack([xs, ys])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This module contains three functions that can plot some aspects of the simple 2d-points-in-a-spiral problem.\n",
    "The functions can be used as is, without looking into their inner workings.\n",
    "You can also use them as inspiration for other ways of visualizing what your neural net does.\n",
    "'''\n",
    "def forward_function(Y_k_mat, omega, my):\n",
    "    vec_for_eta = np.dot(omega, Y_k_mat) + my\n",
    "    return(eta(vec_for_eta))\n",
    "    \n",
    "def last_function(Y_K, omega, my): #Tar inn Y_K\n",
    "    vec_for_eta = np.dot(omega, Y_K) + my\n",
    "    return(eta(vec_for_eta))\n",
    "\n",
    "\n",
    "def plot_progression(Y, C):\n",
    "    '''\n",
    "    This function should make K+1 plots showing how, as the network progresses through its layers,\n",
    "    the datapoints are drawn apart in such a way that they can be separated by a straight line.\n",
    "    \n",
    "    Y: A K+1-by-I-by-2 matrix of the values for each data point in the training set in each layer.\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Y.\n",
    "    '''\n",
    "    for k in range(Y.shape[0]):\n",
    "        show_dots(Y[k,:,:],C.flatten())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_model(forward_function, Ys, C, n):\n",
    "    '''\n",
    "    Make a map that shows what part of the 2d plane is classified as belonging to which spiral arm.\n",
    "    Also plot the training data in Ys, C.\n",
    "    \n",
    "    forward_function: A function that takes one argument, an S-by-2 matrix of S datapoints, and\n",
    "        returns a vector of S classification values.\n",
    "        \n",
    "        Hint: This function will use the weights you have found, so you might want it to be a method on a\n",
    "        class called something like Network or Model.\n",
    "    Ys: An I-by-2 matrix. Corresponding to Y[0,:,:]\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Ys.\n",
    "    n: Number of test-points in each direction. This controls the resolution of the plot.\n",
    "    '''\n",
    "    grid, coordinates = get_discretization(Ys, n)\n",
    "\n",
    "    Z = forward_function(grid, omega, my)\n",
    "    l = np.linspace(0,1,8)\n",
    "    l = np.array([shading(x) for x in l])\n",
    "\n",
    "    plot_contours(*coordinates, Z, l, Ys, C.flatten())\n",
    "\n",
    "\n",
    "def plot_separation(last_function, Ys, C, n):\n",
    "    '''\n",
    "    Show how the training data is represented in the last layer. Also maps the rest of the possible points in the plane.\n",
    "    \n",
    "    last_function: A function that takes one argument, and S-by-2 matrix of S intermediate states in\n",
    "        the network, and retruns a vector of S classification values.\n",
    "        It should multiply by w, add 풮 and evaluate 洧랙.\n",
    "        \n",
    "        Hint: This function will use the weights you have found, so you might want it to be a method on a\n",
    "        class called something like Network or Model.\n",
    "    Ys:An I-by-2 matrix. Corresponding to Y[-1,:,:].\n",
    "    C: An I-by-1 matrix of the labels corresponding to the datra points in Ys.\n",
    "    n: Number of test-points in each direction. This controls the resolution of the plot.\n",
    "    '''\n",
    "    grid, coordinates = get_discretization(Ys, n)\n",
    "\n",
    "    Z = last_function(grid,)\n",
    "    l = np.linspace(0,1,500)\n",
    "\n",
    "    plot_contours(*coordinates, Z, l, Ys, C.flatten())\n",
    "\n",
    "\n",
    "######## Internals\n",
    "\n",
    "\n",
    "def show_dots(positions, labels):\n",
    "    '''Visualize the output of get_data_spiral_2d'''\n",
    "    plt.scatter(x=positions[0,:], y=positions[1,:], s=1, c=labels, cmap='bwr')\n",
    "    plt.axis([-1.2, 1.2, -1.2, 1.2])\n",
    "    plt.axis('square')\n",
    "\n",
    "\n",
    "def plot_contours(box, xcoordinates, ycoordinates, Z, l, Ys, C1):\n",
    "    n = xcoordinates.size\n",
    "    plt.contourf(xcoordinates, ycoordinates, Z.reshape((n,n)), cmap='seismic', levels=l)\n",
    "    plt.contour(xcoordinates, ycoordinates, Z.reshape((n,n)), levels=1, colors='k')\n",
    "    plt.scatter(x=Ys[0,:], y=Ys[1,:], s=1, c=C1, cmap='bwr')\n",
    "    plt.axis(box)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_discretization(Ys, n):\n",
    "    xmin, xmax, ymin, ymax = get_box(Ys)\n",
    "    xcoordinates = np.linspace(xmin, xmax, n)\n",
    "    ycoordinates = np.linspace(ymin, ymax, n)\n",
    "    grid = get_grid(xcoordinates, ycoordinates)\n",
    "    coordinates = ([xmin, xmax, ymin, ymax], xcoordinates, ycoordinates)\n",
    "    return grid, coordinates\n",
    "\n",
    "\n",
    "def get_box(Ys):\n",
    "    xmin = min(Ys[0,:])\n",
    "    xmax = max(Ys[0,:])\n",
    "    xdelta = xmax-xmin\n",
    "    xmin -= 0.2*xdelta\n",
    "    xmax += 0.2*xdelta\n",
    "    ymin = min(Ys[1,:])\n",
    "    ymax = max(Ys[1,:])\n",
    "    ydelta = ymax-ymin\n",
    "    ymin -= 0.2*ydelta\n",
    "    ymax += 0.2*ydelta\n",
    "    return xmin, xmax, ymin, ymax\n",
    "\n",
    "    \n",
    "def get_grid(xcoordinates, ycoordinates):\n",
    "    xv, yv = np.meshgrid(xcoordinates, ycoordinates)\n",
    "    xs = xv.reshape(-1)\n",
    "    ys= yv.reshape(-1)\n",
    "    grid = np.stack([xs,ys])\n",
    "    return grid\n",
    "\n",
    "\n",
    "def shading(x):\n",
    "    return shading1(shading2(x))\n",
    "\n",
    "\n",
    "def shading1(x):\n",
    "    if x == 0.0:\n",
    "        return 0.0\n",
    "    return 0.5 * np.tanh(np.tan(x * np.pi + np.pi / 2.0)) + 0.5\n",
    "\n",
    "\n",
    "def shading2(x):\n",
    "    if x < 0.5:\n",
    "        return 0.5 - np.sqrt(0.25 - x**2)\n",
    "    else:\n",
    "        return 0.5 + np.sqrt(0.25 -(x-1.0)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_1 = labels_1 * 1\n",
    "C_2 = labels_2 * 1\n",
    "\n",
    "plot_separations(last_function(Y_K, omega, my), )\n",
    "\n",
    "plot_progression(Y_k_final, C_1)\n",
    "plot_progression(Y_k_final2, C_2)\n",
    "\n",
    "def plotJ(J_liste):\n",
    "    x_akse = np.arange(len(J_liste))\n",
    "    plt.scatter(x_akse, J_liste)\n",
    "    plt.figure(10)\n",
    "    plt.show()\n",
    "\n",
    "plotJ(J_list1)\n",
    "plotJ(J_list2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
